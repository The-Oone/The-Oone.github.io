[{"content":" 什么是 interface？\nGo 语言中 interface 是一个抽象类型，不涉及具体实现，用于定义一组方法的集合 两个 interface 可以比较吗？\n接口值可以进行比较，基于接口的动态类型和动态值。接口类型不能直接比较。 string 可变嘛？\n在 Go 语言中，string 类型是不可修改的，其本质是字符数组。这意味着一旦你创建了一个字符串，无法直接修改它的内容。如果你想要改变一个字符串的值，你通常需要创建一个新的字符串。 单引号、双引号、反引号区别\n单引号，表示字符常量，用于表示 Unicode 字符，实际上是 int32 别名。处理多语言字符串优势大，例如 utf-8 使用 1-4 个字节表示一个字符，因此不能简单使用 byte[] 处理。 双引号，表示字符串常量 反引号，表示原始字符串字面量。内容不需要转义 Go 的数据类型有哪些\n基本数据类型：int，float，string，bool，complex，rune(int32)，byte(uint8) struct，slice，array，map，channel，interface，function，指针 什么是 defer 语句？多个 defer 语句如何运行？\ndefer 是 Go 语言的一种延迟调用机制，defer 后面的函数只有在当前函数执行完成之后才会被执行。当 Go 看见 defer 之后，会将其压入栈中，因此多个 defer 是遵循先进后出原则执行。 defer 可以嵌套，依旧遵循先进后出原则，并且 defer 在发生 panic 之后也依然有效。 介绍一下 init 函数\ninit 函数在包被导入时自动调用，无需显式调用 一个包可以定义多个 init 函数，按同个包内按照定义顺序执行，不同包按导入顺序 没有返回值和参数，且优于其他函数 只能在包级别定义，运行期间只会执行一次 string 和 []byte 相互转换会不会发生内存拷贝\n标准的转换方法是会的，当一个字符转转成一个字节切片时，Go 会创建一个新的字节数组，并将数据复制到这个新数组中 强制转换不会，但是不安全 switch-case 语句\n1 2 3 4 5 6 7 8 switch simpleStatement; condition { case expression1, expression2: statements case expression3: statements default: statements } switch 包含两个部分，分号前的是初始化器，分号之后是需要检查的值，可以两个部分都使用，或是使用一个，或者一个都不用\nGo 语言中匹配到一个 case 条件执行完对应的逻辑之后就会跳出这个 switch 语句，如果不想要隐式退出的话可以使用 fallthrough 语句来继续下一个 case 的处理逻辑。\nswitch语句不仅可以处理值，还可以处理类型。\n1 2 3 4 5 6 7 8 9 10 11 12 func main() { var i interface{} = \u0026#34;hello\u0026#34; switch v := i.(type) { case int: fmt.Println(\u0026#34;i is an int and its value is\u0026#34;, v) case string: fmt.Println(\u0026#34;i is a string and its value is\u0026#34;, v) default: fmt.Println(\u0026#34;Unknown type\u0026#34;) } } Go 拼接字符串方法\n使用 + ：\n1 2 3 4 5 func main() { s := \u0026#34;hello \u0026#34; s += \u0026#34;world\u0026#34; fmt.Println(s) // hello world } 字符串格式化函数 fmt.Sprintf：\n1 2 3 4 5 func main() { s := \u0026#34;hello\u0026#34; s = fmt.Sprintf(\u0026#34;%s%s\u0026#34;, s, s) fmt.Println(s) // hellohello } string.Builder：\n1 2 3 4 5 6 func main() { var builder strings.Builder builder.WriteString(\u0026#34;hello \u0026#34;) builder.WriteString(\u0026#34;world\u0026#34;) fmt.Println(builder.String()) // hello world } bytes.Buffer：\n1 2 3 4 5 6 func main() { buf := new(bytes.Buffer) buf.WriteString(\u0026#34;hello\u0026#34;) buf.WriteString(\u0026#34;world\u0026#34;) fmt.Println(buf.String()) } strings.join：\n1 2 3 4 5 func main() { baseSlice := []string{\u0026#34;hello\u0026#34;, \u0026#34;world\u0026#34;} fmt.Println(baseSlice) // [hello world] fmt.Println(strings.Join(baseSlice, \u0026#34;\u0026#34;)) // helloworld } 切片 + append：\n1 2 3 4 5 6 func main() { buf := make([]byte, 0) base := \u0026#34;hello\u0026#34; buf = append(buf, base...) fmt.Println(string(buf)) } 性能对比\n使用 go test -bench=\u0026quot;.\u0026quot; -run=none -benchmem 对上述六种方法进行新跟那个测试\n利用 pprof 进行内存和 CPU 分析\n不难发现，strings.join、string.Builder 的性能比较优越。\n如何实现可变参数\n1 2 3 4 5 6 // name ...Type 声明一个 Type 类型的可变参数 // 这是官方库中 Println 的设计，接收任意个接口 type any = interface{} func Println(a ...any) (n int, err error) { return Fprintln(os.Stdout, a...) } 可变参数就是一个占位符，你可以将 1 个或者多个参数赋值给这个占位符，这样不管实际参数的数量是多少，都能交给可变参数来处理 uintptr 和 unsafe.Pointer 有那些区别\nGo 是一门强类型的语言，它对指针的操作非常严格。但是，有时我们需要绕过类型系统，直接操作内存地址，比如调用 C 语言的函数或者实现一些底层的功能。这时，我们就需要用到 golang 的内置包 unsafe 和它提供的两种特殊的类型：uintptr 和 unsafe.Pointer。\nuintptr 是 golang 的内置类型，它是一个能够存储指针的整数类型。它的底层类型是 int，它的大小和平台相关，通常是 32 位或者 64 位。我们可以把任何类型的指针转换成 uintptr，也可以把 uintptr 转换成任何类型的指针。例如：\n1 2 3 4 5 var s string = \u0026#34;hello\u0026#34; var p *string = \u0026amp;s var u uintptr = uintptr(unsafe.Pointer(p)) // 把 *string 类型的指针转换成 uintptr 类型的整数 var q *string = (*string)(unsafe.Pointer(u)) // 把 uintptr 类型的整数转换成 *string 类型的指针 fmt.Println(*q) // 输出 hello unsafe.Pointer 是 golang 的内置类型，它是一种通用的指针类型，可以指向任何类型的值。它的作用是，可以把不同类型的指针相互转换，而不用经过 uintptr 的中间转换。例如：\n1 2 3 4 5 var s string = \u0026#34;world\u0026#34; var p *string = \u0026amp;s var q unsafe.Pointer = unsafe.Pointer(p) // 把 *string 类型的指针转换成 unsafe.Pointer 类型的指针 var r *int = (*int)(q) // 把 unsafe.Pointer 类型的指针转换成 *int 类型的指针 fmt.Println(*r) // 输出一个随机的整数，因为字符串的内存布局和整数的不同 uintptr 和 unsafe.Pointer 的区别和联系可以总结如下：\nuintptr 是一种整数类型，unsafe.Pointer 是一种指针类型。 uintptr 可以进行算术运算，unsafe.Pointer 不可以进行算术运算。 uintptr 不会被 GC 识别和追踪，unsafe.Pointer 会被 GC 识别和追踪。 uintptr 和 unsafe.Pointer 可以相互转换，也可以和任何类型的指针相互转换。 Go 的类型断言\n类型断言是Go语言中将一个接口类型变量转换为指定具体类型的一种技术手段。它可以检测存储在接口内部的具体类型，从而实现对不同类型数据的灵活处理。\n基本语法\n1 2 value, ok := x.(T) // 安全的断言方式 value := x.(T) // 这样也可以，但是如果断言失败会引发 panic x 是一个接口类型的变量，T 是希望断言的类型。value 将会是 x 转换为类型 T 后的值，ok 是一个布尔值，当类型断言成功时为 true，失败时为 false 。\n类型断言的必要条件是 x 必须是接口类型，非接口类型的 x 不能做类型断言。\ntype-switch 结构\n1 2 3 4 5 6 7 8 switch v := x.(type) { case int: // 处理int类型 case string: // 处理string类型 default: // 处理其他类型 } ","date":"2025-01-19T17:09:48+08:00","permalink":"https://the-oone.github.io/p/%E5%85%B3%E4%BA%8E-go-%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98/","title":"关于 Go 的一些问题"},{"content":"线程通信 进程通信就是指进程之间的信息交换。\n共享存储 多个线程直接访问同一块内存用来通信，使用互斥锁对内存进行保护。这种方法抽象层次低，耦合度高，还有可能导致死锁问题。\n基于数据结构的通信 多个进程共用某些数据结构，实现诸进程间的信息交换。由用户（程序员）负责同步处理，OS提供共享存储器。 低级通信：可以传递少量数据，效率低 基于共享存储区的通信 多个进程可通过对共享存储区中的数据读或写来实现通信。 高级通信：可以传递大量数据，效率高。 消息传递 进程通信采用消息传递方式时，进程间的数据交换会以格式化的信息 (Message) 为单位。进程通过操作系统提供的\u0026quot;发送消息/接受消息\u0026quot;两个原语进行数据交换。\n直接消息传递 发送方将消息直接挂到接收方的消息队列中 间接消息传递 发送进程发送消息到中间缓冲区 接收进程在中间缓冲区接收线程 管道通信 管道是指用于连接读写进程的一个共享文件，又名pipe文件。进程通信采用管道通信方式时，操作系统会在内存中开辟的一个大小固定的缓冲区，进程需要按照规则进行通信。其中规则如下：\n一条管道只能实现半双工通信，即 某一时间段内只能实现单向的数据传输。 各个进程只能互斥的访问管道，即 当一个进程在写的时候，另外一个进程不能读，反之亦然。 数据会以字符流的形式写入管道，当管道写满时，写进程的write()系统调用将会被阻塞，直到读进程将数据取走；当读进程将数据全部取走后，管道变空，此时读进程的read()系统调用将被阻塞。 如果没写满，就不允许读；如果没读空，就不允许写。 CSP 并发模型 CSP（Communicating Sequential Processes，通信顺序进程）并发模型倡导使用通信的手段来进行共享内存，继而实现多个线程之间的通信。这也是 Golang 倡导使用的并发模型，通过 Channel 来使用。其中有两个核心概念：\n并发实体：Go 使用 Goroutine，Goroutine 之间相互独立、且并发执行 通道：Go 使用 Channel，并发实体之间使用通道发送消息 Go 的并发 原子操作 原子操作是最基础的并发原语。Go 官方在 atomic 包中提供了操作，具体详见 Go八股之Mutex\nChannel channel 管道，高级同步原语，goroutine之间通信的桥梁，详见 Go八股之Channel\n基本并发原语 sync.Mutex：互斥锁可以限制对临界资源的访问，保证同一时刻只有一个 Goroutine 访问共享资源\n1 2 3 4 5 mutex := \u0026amp;sync.Mutex{} mutex.Lock() // 临界区操作 mutex.Unlock() sync.RWMutex：读写锁可以限制对临界资源的访问，保证同一时刻只有一个 Goroutine 写共享资源，允许多个 Goroutine 读共享资源\n1 2 3 4 5 6 7 8 9 mutex := \u0026amp;sync.RWMutex{} mutex.Lock() // 临界区写操作 mutex.Unlock() mutex.RLock() // 临界区读操作 mutex.RUnlock() sync.WaitGroup：等待一组 Goroutine 的返回。\nsync.WaitGroup拥有一个内部计数器。当计数器等于0时，则Wait()方法会立即返回。否则它将阻塞执行Wait()方法的goroutine直到计数器等于0时为止。\n要增加计数器，我们必须使用Add(int)方法。要减少它，我们可以使用Done()（将计数器减1），也可以传递负数给Add方法把计数器减少指定大小，Done()方法底层就是通过Add(-1)实现的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 wg := \u0026amp;sync.WaitGroup{} // 启动 5 个 Goroutine for i := 0; i \u0026lt; 5; i++ { wg.Add(1) go func() { // 操作 wg.Done() }() } wg.Wait() // 继续往下执行... sync.Map：线程安全的 Map\n使用 Store(interface {}，interface {}) 添加元素。 使用 Load(interface {}) interface {} 检索元素。 使用 Delete(interface {}) 删除元素。 使用 LoadOrStore(interface {}，interface {}) (interface {}，bool) 检索或添加之前不存在的元素。如果键之前在map中存在，则返回的布尔值为true。 使用 Range 遍历元素。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 m := \u0026amp;sync.Map{} // 添加元素 m.Store(1, \u0026#34;one\u0026#34;) m.Store(2, \u0026#34;two\u0026#34;) // 获取元素1 value, contains := m.Load(1) if contains { fmt.Printf(\u0026#34;%s\\n\u0026#34;, value.(string)) } // 返回已存value，否则把指定的键值存储到map中 value, loaded := m.LoadOrStore(3, \u0026#34;three\u0026#34;) if !loaded { fmt.Printf(\u0026#34;%s\\n\u0026#34;, value.(string)) } m.Delete(3) // 迭代所有元素 m.Range(func(key, value interface{}) bool { fmt.Printf(\u0026#34;%d: %s\\n\u0026#34;, key.(int), value.(string)) return true }) sync.Pool：可以将暂时将不用的对象缓存起来，待下次需要的时候直接使用，不用再次经过内存分配，复用对象的内存，减轻 GC 的压力，提升系统的性能。\nGet() interface{} 用来从并发池中取出元素。 Put(interface{}) 将一个对象加入并发池。 1 2 3 4 5 6 7 8 9 10 11 12 pool := \u0026amp;sync.Pool{} pool.Put(NewConnection(1)) pool.Put(NewConnection(2)) pool.Put(NewConnection(3)) connection := pool.Get().(*Connection) fmt.Printf(\u0026#34;%d\\n\u0026#34;, connection.id) connection = pool.Get().(*Connection) fmt.Printf(\u0026#34;%d\\n\u0026#34;, connection.id) connection = pool.Get().(*Connection) fmt.Printf(\u0026#34;%d\\n\u0026#34;, connection.id) sync.Once：确保一个函数仅执行一次\n1 2 3 4 5 6 7 8 9 once := \u0026amp;sync.Once{} for i := 0; i \u0026lt; 4; i++ { i := i go func() { once.Do(func() { fmt.Printf(\u0026#34;first %d\\n\u0026#34;, i) }) }() } sync.Cond：发出信号（一对一）或广播信号（一对多）到 Goroutine\nsync.Context：上下文信息传递、提供超时和取消机制、控制子 goroutine 的执行\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 package main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { ctx, cancel := context.WithCancel(context.Background()) go func() { defer func() { fmt.Println(\u0026#34;goroutine exit\u0026#34;) }() for { select { case \u0026lt;-ctx.Done(): fmt.Println(\u0026#34;receive cancel signal!\u0026#34;) return default: fmt.Println(\u0026#34;default\u0026#34;) time.Sleep(time.Second) } } }() time.Sleep(time.Second) cancel() time.Sleep(2 * time.Second) } 拓展并发原语 errGroup 提供了一种方便的方式来跟踪和处理多个 Goroutine 中的错误。它可以让你启动多个 Goroutine ，并等待它们全部完成，或者在任何一个 Goroutine 返回错误时立即取消所有其他 Goroutine。 在 errgroup 包的源码中，它主要使用了 sync.WaitGroup 和 context.Context 来实现多个goroutine的管理和错误处理。 Semaphore go中的semaphore，提供sleep和wakeup原语，使其能够在其它同步原语中的竞争情况下使用。当一个goroutine需要休眠时，将其进行集中存放，当需要wakeup时，再将其取出，重新放入调度器中。 通过信号量来限制并行的goroutine数量，达到最大的maxWorkers数量，Acquire将会阻塞，直到其中一个goroutine执行完成，释放出信号量。 SingleFlight SingleFlight 提供了重复函数调用抑制机制，使用它可以避免同时进行相同的函数调用。第一个调用未完成时后续的重复调用会等待，当第一个调用完成时则会与它们分享结果，这样以来虽然只执行了一次函数调用但是所有调用都拿到了最终的调用结果。 ","date":"2025-01-18T16:37:56+08:00","permalink":"https://the-oone.github.io/p/go%E5%85%AB%E8%82%A1%E4%B9%8B%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/","title":"Go八股之并发编程"},{"content":"锁 锁是多线程编程中的一种同步机制，用于控制对共享资源的访问。\n悲观锁 悲观锁总是假设最坏的情况，认为共享资源每次被访问的时候就会出现问题(比如共享数据被修改)，所以每次在获取资源操作的时候都会上锁，这样其他线程想拿到这个资源就会阻塞直到锁被上一个持有者释放。也就是说，共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程。\n乐观锁 乐观锁总是假设最好的情况，认为共享资源每次被访问的时候不会出现问题，线程可以不停地执行，无需加锁也无需等待，只是在提交修改的时候去验证对应的资源（也就是数据）是否被其它线程修改。\nGo Mutex Go sync 包提供了两种锁类型：互斥锁 sync.Mutex 、读写互斥锁 sync.RWMutex。二者都属于悲观锁\n底层数据结构 1 2 3 4 type Mutex struct { state int32 sema uint32 } state 表示互斥锁的状态\n低 1 bit 是mutexLocked，表示互斥锁是否已经被加锁\n低 2 bit 是 mutexWoken，表示互斥锁是否有被唤醒的 Goroutine\n低 3 bit 是 mutexStarving，表示互斥锁是否处于饥饿状态\n剩下 29 bit 表示在这个互斥锁上等待队列的 Goroutine 数量\nsema 表示信号量，mutex 阻塞队列的定位是通过这个变量来实现的，从而实现 goroutine 的阻塞和唤醒。\n加锁 首先尝试使用原子操作快速获取锁，如果锁处于初始状态（未被锁定且无等待队列），则直接获取锁并返回，这是快速路径。 如果快速获取失败，则进入慢路径。在慢路径中，会判断锁是否已被锁定且可自旋。如果是，则尝试设置唤醒标志并进行自旋等待，即执行空循环一段时间，期望锁能够快速释放。 如果自旋等待后仍未获取锁，或者锁不满足自旋条件，则将当前 Goroutine 加入等待队列。根据锁的当前状态（正常模式或饥饿模式），设置相应的队列信息。 如果锁处于饥饿模式，当前 Goroutine 会直接阻塞，直到被唤醒并获取锁。如果处于正常模式，被唤醒的 Goroutine 需要与新到达的 Goroutine 竞争锁。 解锁 解锁时，首先使用原子操作更新锁的状态，将锁标记为未锁定，并根据需要更新等待队列信息。 如果有等待的 Goroutine，并且满足饥饿模式切换条件（如等待队列中只有一个等待者或等待时间较短），则将锁切换到正常模式。 唤醒等待队列中的一个 Goroutine，使其有机会获取锁。 自旋和阻塞 Goroutine 在没有获取到锁时有以下两种处理方式：\n一种是没有获取到锁的线程就一直循环等待判断该资源是否已经释放锁，这种锁也叫做自旋锁，它不用将线程阻塞起来， 适用于并发低且程序执行时间短的场景，缺点是cpu占用较高 另外一种处理方式就是把自己阻塞起来，会释放CPU给其他线程，内核会将线程置为睡眠状态，等到锁被释放后，内核会在合适的时机唤醒该线程，适用于高并发场景，缺点是有线程上下文切换的开销 而进入自选态需要满足以下条件：\n锁已被占用，并且锁不处于饥饿模式。 积累的自旋次数小于最大自旋次数（active_spin=4）。 cpu 核数大于 1。 有空闲的 P。 当前 goroutine 所挂载的 P 下，本地待运行队列为空。 小结 在 Lock() 之前使用 Unlock() 会导致 panic 异常 使用 Lock() 加锁后，再次 Lock() 会导致死锁（不支持重入），需Unlock()解锁后才能再加锁 锁定状态与 goroutine 没有关联，一个 goroutine 可以 Lock，另一个 goroutine 可以 Unlock Goroutine 抢锁模式 正常模式（非公平锁） 在刚开始的时候，是处于正常模式（Barging），也就是，当一个G1持有着一个锁的时候，G2会自旋的去尝试获取这个锁\n当自旋超过4次还没有能获取到锁的时候，这个G2就会被加入到获取锁的等待队列里面，并阻塞等待唤醒\n正常模式下，所有等待锁的 goroutine 按照 FIFO(先进先出)顺序等待。唤醒的goroutine 不会直接拥有锁，而是会和新请求锁的 goroutine 竞争锁。新请求锁的 goroutine 具有优势：它正在 CPU 上执行，而且可能有好几个，所以刚刚唤醒的 goroutine 有很大可能在锁竞争中失败，长时间获取不到锁，就会切换到饥饿模式\n饥饿模式（公平锁） 当一个 goroutine 等待锁时间超过 1 毫秒时，它可能会遇到饥饿问题。 在版本1.9中，这种场景下Go Mutex 切换到饥饿模式（handoff），解决饥饿问题。回归正常模式满足两个条件任何一个：\nGoutine 的执行时间小于 1ms 等待队列已经清空 小结 对于两种模式，正常模式下的性能是最好的，goroutine 可以连续多次获取锁，饥饿模式解决了取锁公平的问题，但是性能会下降，其实是性能和公平的 一个平衡模式。\nsync.RWMutex 底层数据结构 1 2 3 4 5 6 7 type RWMutex struct { w Mutex // 互斥锁 writerSem uint32 // 信号量，用于写等待读 readerSem uint32 // 信号量，用于读等待写 readerCount int32 // 当前执行读的 goroutine 数量 readerWait int32 // 被阻塞的准备读的 goroutine 的数量 } 读锁 1 2 func (rw *RWMutex) RLock() // 加读锁 func (rw *RWMutex) RUnlock() // 释放读锁 先通过原子操作将readerCount加1 如果readerCount\u0026gt;=0就直接返回，所以如果只有获取读取锁的操作，那么其成本只有一个原子操作 当readerCount\u0026lt;0时，说明当前有写锁，当前协程将借助信号量陷入等待状态，如果获取到信号量则直接退出，没有获取到信号量时的逻辑与互斥锁的逻辑相似 读锁解锁时，如果当前没有写锁，则其成本只有一个原子操作并直接退出 如果当前有写锁正在等待，则调用rUnlockSlow判断当前是否为最后一个被释放的读锁，如果是则需要 增加信号量并唤醒写锁 写锁 1 2 func (rw *RWMutex) Lock() // 加写锁 func (rw *RWMutex) Unlock() // 释放写锁 写锁申请时必须先获取互斥锁，因为它复用了互斥锁的功能。接着readerCount减去 rwmutexMaxReaders阻止后续读操作 获取到互斥锁并不一定能直接获取写锁，如果当前已经有其它Goroutine持有互斥锁的读锁，那么当前 协程会加入全局等待队列并进入休眠状态，当最后一个读锁被释放时，会唤醒该协程 解锁时，调用Unlock方法，将readerCount加上rwmutexMaxReader，表示不会阻塞后序的读锁，依次 唤醒所有等待中的读锁，当所有的读锁唤醒完毕后会释放互斥锁 小结 读锁或写锁在 Lock() 之前使用 Unlock() 会导致 panic 异常 使用 Lock() 加锁后，再次 Lock() 会导致死锁（不支持重入），需Unlock()解锁后才能再加锁 锁定状态与 goroutine 没有关联，一个 goroutine 可以 RLock（Lock），另一个 goroutine 可以 RUnlock（Unlock） 递归锁 可重入锁又称为递归锁，是指在同一个线程在外层方法获取锁的时候，在进入该线程的内层方法时会自动获取锁，不会因为之前已经获取过还没释放再次加锁导致死锁。\nGo 里面的 Mutex 不是可重入的锁。Mutex 的实现中没有记录哪个 goroutine 拥有这把锁，理论上，任何 goroutine 都可以随意地 Unlock 这把锁，所以没办法计算重入条件，并且 Mutex 重复 Lock 会导致死锁。\n如果要实现递归锁，需要以下两个条件：\n记住持有锁的线程 计算冲入次数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 package main import ( \u0026#34;bytes\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;runtime\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;sync/atomic\u0026#34; ) type ReentrantLock struct { sync.Mutex recursion int32 // 这个goroutine 重入的次数 owner int64 // 当前持有锁的goroutine id } // Get returns the id of the current goroutine. func GetGoroutineID() int64 { var buf [64]byte var s = buf[:runtime.Stack(buf[:], false)] s = s[len(\u0026#34;goroutine \u0026#34;):] s = s[:bytes.IndexByte(s, \u0026#39; \u0026#39;)] gid, _ := strconv.ParseInt(string(s), 10, 64) return gid } func NewReentrantLock() sync.Locker { res := \u0026amp;ReentrantLock{ Mutex: sync.Mutex{}, recursion: 0, owner: 0, } return res } // ReentrantMutex 包装一个Mutex,实现可重入 type ReentrantMutex struct { sync.Mutex owner int64 // 当前持有锁的goroutine id recursion int32 // 这个goroutine 重入的次数 } func (m *ReentrantMutex) Lock() { gid := GetGoroutineID() // 如果当前持有锁的goroutine就是这次调用的goroutine,说明是重入 if atomic.LoadInt64(\u0026amp;m.owner) == gid { m.recursion++ return } m.Mutex.Lock() // 获得锁的goroutine第一次调用，记录下它的goroutine id,调用次数加1 atomic.StoreInt64(\u0026amp;m.owner, gid) m.recursion = 1 } func (m *ReentrantMutex) Unlock() { gid := GetGoroutineID() // 非持有锁的goroutine尝试释放锁，错误的使用 if atomic.LoadInt64(\u0026amp;m.owner) != gid { panic(fmt.Sprintf(\u0026#34;wrong the owner(%d): %d!\u0026#34;, m.owner, gid)) } // 调用次数减1 m.recursion-- if m.recursion != 0 { // 如果这个goroutine还没有完全释放，则直接返回 return } // 此goroutine最后一次调用，需要释放锁 atomic.StoreInt64(\u0026amp;m.owner, -1) m.Mutex.Unlock() } func main() { var mutex = \u0026amp;ReentrantMutex{} mutex.Lock() mutex.Lock() fmt.Println(111) mutex.Unlock() mutex.Unlock() } Go 原子操作 Go atomic 包是最轻量级的锁（也称无锁结构），可以在不形成临界区和创建互斥量的情况下完成并发安全的值替换操作，支持 int32/int64/uint32/uint64/uintptr 的基础操作（增减、交换、载入、存储等）。\nAdd 操作 1 2 3 4 5 func AddInt32(addr *int32, delta int32) (new int32) func AddInt64(addr *int64, delta int64) (new int64) func AddUint32(addr *uint32, delta uint32) (new uint32) func AddUint64(addr *uint64, delta uint64) (new uint64) func AddUintptr(addr *uintptr, delta uintptr) (new uintptr) Load 操作 1 2 3 4 5 6 7 8 func LoadInt32( addr *int32)(val int32) func LoadInt64(addr *int64)(val int64) func LoadPointer(addr *unsafe.Pointer) (val unsafe.Pointer) func LoadUint32( addr *uint32)(val uint32) func LoadUint64(addr *uint64) (val uint64) func LoadUintptr(addr *uintptr) (val uintptr) //特殊类型:Value类型，常用于配置变更 func (v *Value) Load() (x interface{}){} CAS 操作 1 2 3 4 5 6 func CompareAndSwapInt32(addr *int32,old,new int32)(swapped bool) func CompareAndSwapInt64(addr *int64,old,new int64) (swapped bool) func CompareAndSwapPointer(addr *unsafe.Pointer，old,new unsafe.Pointer) (swapped bool) func CompareAndSwapUint32(addr *uint32,old,new uint32)(swapped bool) func CompareAndSwapUint64(addr *uint64,old,new uint64) (swapped bool) func CompareAndSwapUintptr(addr *uintptr,old,new uintptr) (swapped bool) Swap 操作 1 2 3 4 5 6 func SwapInt32(addr *int32, new int32) (old int32) func SwapInt64(addr *int64, new int64) (old int64) func SwapPointer(addr *unsafe.Pointer, new unsafe.Pointer) (old unsafe.Pointer) func SwapUint32(addr *uint32, new uint32) (old uint32) func SwapUint64(addr *uint64, new uint64) (old uint64) func SwapUintptr(addr *uintptr, new uintptr) (old uintptr) Store 操作 1 2 3 4 5 6 7 8 func StoreInt32(addr *int32, val int32) func StoreInt64(addr *int64, val int64) func StorePointer(addr *unsafe.Pointer, val unsafe.Pointer) func StoreUint32(addr *uint32, val uint32) func StoreUint64(addr *uint64, val uint64) func StoreUintptr(addr *uintptr, val uintptr) // 特殊类型： Value类型，常用于配置变更 func (v *Value) Store(x interface{}) 原子操作 VS 锁 原子操作 锁 实现原理 底层硬件支持 原子操作 + 信号量 范围 单个指令 临界区（多条指令） 性能 性能较高 性能较低 类别 乐观锁 悲观锁 ","date":"2025-01-18T12:17:11+08:00","permalink":"https://the-oone.github.io/p/go%E5%85%AB%E8%82%A1%E4%B9%8Bmutex/","title":"Go八股之Mutex"},{"content":"底层实现原理 Go中 的 channel 是一个队列，遵循先进先出的原则，负责协程之间的通信（Go 语言提倡不要通过共享内存来通信，而要通过通信来实现内存共享，CSP(Communicating Sequential Process)并发模型，就是通过 goroutine 和 channel 来实现的）。\n底层数据结构 通过 var 声明或者 make 函数创建的 channel 是一个存储在函数栈帧上的指针，占用8个字节，指向堆上 的 hchan 结构体：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 type hchan struct { qcount uint // 循环数组中的数据个数 dataqsiz uint // 循环数组的长度 buf unsafe.Pointer // 指向循环数组的指针 elemsize uint16 // 元素的大小 closed uint32 // channel 关闭标志 timer *timer // timer feeding this chan elemtype *_type // 元素类型 sendx uint // 下一次写下标的位置 recvx uint // 下一次读下标的位置 recvq waitq // 读等待队列 sendq waitq // 写等待队列 lock mutex // 互斥锁 } 等待队列是一个双向链表，包含一个头节点和一个尾节点。每个节点是一个sudog结构体变量，记录哪个协程在等待，等待的是哪个channel，等待发送/接收的数据在哪里。\n1 2 3 4 5 6 7 8 9 10 11 12 13 type waitq struct{ first *sudog // 队列头 last *sudog // 队列尾 } type sudog struct{ g *g // 等待的 Goroutine next *sudog prev *sudog elem unsafe.Pointer // 发送/读取数据的指针 c *hchan // 等待的 Channel ... } Channel 使用操作 创建 1 2 3 4 // 创建有缓冲 channel，缓冲大小为 3 ch := make(chan int, 3) // 创建无缓冲 channel ch := make(chan int) 如果是无缓冲的 channel，会直接给 hchan 分配内存 如果是有缓冲的 channel，并且元素不包含指针，那么会为 hchan 和底层数组分配一段连续的地址 如果是有缓冲的 channel，并且元素包含指针，那么会为 hchan 和底层数组分别分配地址 发送 若 channel 的读等待队列存在接收者 goroutine，那么将数据直接发送给第一个等待的 goroutine，唤醒接收的 goroutine 若 channel 的读等待队列不存在接收者 goroutine 若循环数组 buf 未满，那么将会把数据发送到循环数组buf的队尾 如果循环数组buf已满，这个时候就会走阻塞发送的流程，将当前goroutine加入写等待队列，并挂起等待唤醒 接收 如果 channel 的写等待队列存在发送者 goroutine 如果是无缓冲 channel，直接从第一个发送者 goroutine 那里把数据拷贝给接收变量，唤醒发送的 goroutine 如果是有缓冲 channel（已满），将循环数组 buf 的队首元素拷贝给接收变量，将第一个发送者goroutine 的数据拷贝到 buf循环数组队尾，唤醒发送的 goroutine 如果 channel 的写等待队列不存在发送者goroutine 如果循环数组 buf 非空，将循环数组buf的队首元素拷贝给接收变量 如果循环数组 buf 为空，这个时候就会走阻塞接收的流程，将当前 goroutine 加入读等待队列，并挂起等待唤醒 Channel 使用场景 循环读取 Channel 数据 使用for-range读取channel，这样既安全又便利，当channel关闭时，for循环会自动退出，无需主动监测channel是否关闭，可以防止读取已经关闭的channel，造成读到数据为通道所存储的数据类型的零值。\n1 2 3 for x := range ch{ fmt.Println(x) } 多重返回判断 Channel 关闭状态 读已关闭的channel会得到零值，如果不确定channel，需要使用ok进行检测。\n1 2 3 if v, ok := \u0026lt;- ch; ok { // ok 会接收到 channel 的状态，true 表示未关闭 fmt.Println(v) } 使用 select 处理多 Channel select可以同时监控多个通道的情况，只处理未阻塞的case。当通道为nil时，对应的case永远为阻塞，无论读写。特殊关注：普通情况下，对nil的通道写操作是要panic的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 func main() { ch1 := make(chan int) ch2 := make(chan int) go func() { for { ch1\u0026lt;-1 } }() go func() { for { ch2\u0026lt;-2 } }() for i := 0; i \u0026lt; 10; i++ { select { case \u0026lt;-ch1: fmt.Println(\u0026#34;Selected ch1\u0026#34;) case \u0026lt;-ch2: fmt.Println(\u0026#34;Selected ch2\u0026#34;) } } } 使用channel的声明控制读写权限 如果协程对某个channel只有写操作，则这个channel声明为只写。\n如果协程对某个channel只有读操作，则这个channe声明为只读。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // 只有 generator 进行对 outCh 进行写操作，返回声明 // \u0026lt;-chan int，可以防止其他协程乱用此通道，造成隐藏 bug func generator(int n) \u0026lt;-chan int { outCh := make(chan int) go func(){ for i:=0;i\u0026lt;n;i++{ outCh\u0026lt;-i } }() return outCh } // consumer只读inCh的数据，声明为\u0026lt;-chan int // 可以防止它向inCh写数据 func consumer(inCh \u0026lt;-chan int) { for x := range inCh { fmt.Println(x) } } 使用缓冲channel增强并发 有缓冲通道可供多个协程同时处理，在一定程度可提高并发性。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 // 无缓冲 ch1 := make(chan int) ch2 := make(chan int, 0) // 有缓冲 ch3 := make(chan int, 1) func test() { inCh := generator(100) outCh := make(chan int, 10) // 使用5个 do 协程同时处理输入数据 var wg sync.WaitGroup wg.Add(5) for i := 0; i \u0026lt; 5; i++ { go do(inCh, outCh, \u0026amp;wg) } go func() { wg.Wait() close(outCh) }() for r := range outCh { fmt.Println(r) } } func generator(n int) \u0026lt;-chan int { outCh := make(chan int) go func() { for i := 0; i \u0026lt; n; i++ { outCh \u0026lt;- i } close(outCh) }() return outCh } func do(inCh \u0026lt;-chan int, outCh chan\u0026lt;- int, wg *sync.WaitGroup) { for v := range inCh { outCh \u0026lt;- v * v } wg.Done() } 为操作加上超时 使用select和time.After，看操作和定时器哪个先返回，处理先完成的，就达到了超时控制的效果\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 func doWithTimeOut(timeout time.Duration) (int, error) { select { case ret := \u0026lt;-do(): return ret, nil case \u0026lt;-time.After(timeout): return 0, errors.New(\u0026#34;timeout\u0026#34;) } } func do() \u0026lt;-chan int { outCh := make(chan int) go func() { // do work }() return outCh } 使用time实现channel无阻塞读写 为操作加上超时的扩展，这里的操作是channel的读或写\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 func unBlockRead(ch chan int) (x int, err error) { select { case x = \u0026lt;-ch: return x, nil case \u0026lt;-time.After(time.Microsecond): return 0, errors.New(\u0026#34;read time out\u0026#34;) } } func unBlockWrite(ch chan int, x int) (err error) { select { case ch \u0026lt;- x: return nil case \u0026lt;-time.After(time.Microsecond): return errors.New(\u0026#34;read time out\u0026#34;) } } close(ch) 关闭所有下游协程 退出时，显示通知所有协程退出。所有读 ch 的协程都会收到close(ch)的信号\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 func (h *Handler) Stop() { close(h.stopCh) // 可以使用WaitGroup等待所有协程退出 } // 收到停止后，不再处理请求 func (h *Handler) loop() error { for { select { case req := \u0026lt;-h.reqCh: go handle(req) case \u0026lt;-h.stopCh: return } } } 使用chan struct{}作为信号 channel 1 2 3 4 5 // 只是要给所有协程发送退出的信号 type Handler struct { stopCh chan struct{} reqCh chan *Request } 使用 channel 传递结构体的指针 channel 本质上传递的是数据的拷贝，拷贝的数据越小传输效率越高，传递结构体指针，比传递结构体更高效\n1 2 3 4 reqCh chan *Request // 好过 reqCh chan Request 使用channel传递channel 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) func main() { reqs := []int{1, 2, 3, 4, 5, 6, 7, 8, 9} // 存放结果的channel的channel outs := make(chan chan int, len(reqs)) var wg sync.WaitGroup wg.Add(len(reqs)) for _, x := range reqs { o := handle(\u0026amp;wg, x) outs \u0026lt;- o } go func() { wg.Wait() close(outs) }() // 读取结果，结果有序 for o := range outs { fmt.Println(\u0026lt;-o) } } // handle 处理请求，耗时随机模拟 func handle(wg *sync.WaitGroup, a int) chan int { out := make(chan int) go func() { time.Sleep(time.Duration(rand.Intn(3)) * time.Second) out \u0026lt;- a wg.Done() }() return out } 控制 Goroutine 并发执行顺序 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 var wg sync.WaitGroup func main() { ch1 := make(chan struct{}, 1) ch2 := make(chan struct{}, 1) ch3 := make(chan struct{}, 1) ch1 \u0026lt;- struct{}{} wg.Add(3) start := time.Now().Unix() go print(\u0026#34;gorouine1\u0026#34;, ch1, ch2) go print(\u0026#34;gorouine2\u0026#34;, ch2, ch3) go print(\u0026#34;gorouine3\u0026#34;, ch3, ch1) wg.Wait() end := time.Now().Unix() fmt.Printf(\u0026#34;duration:%d\\n\u0026#34;, end-start) } func print(gorouine string, inputchan chan struct{}, outchan chan struct{}) { // 模拟内部操作耗时 time.Sleep(1 * time.Second) select { case \u0026lt;-inputchan: fmt.Printf(\u0026#34;%s\\n\u0026#34;, gorouine) outchan \u0026lt;- struct{}{} } wg.Done() } Channel 特点 三种模式\n单向通道的写操作 单向通道的读操作 双向通道的读写操作 创建 make(chan\u0026lt;-int) make(\u0026lt;- chan int) make(chan int) 三种状态\n未初始化（nil） 关闭（closed） 正常（active） 关闭 channel panic panic 正常关闭 发送数据 死锁，永远阻塞 panic 阻塞或成功发送 接收数据 死锁，永远阻塞 缓冲区为空为零值，否则继续读 阻塞或者成功接收 有1个特殊场景：当nil的通道在select的某个case中时，这个case会阻塞，但不会造成死锁。\n一个 channel不能多次关闭，会导致painc\n如果多个 goroutine 都监听同一个 channel，那么 channel 上的数据都可能随机被某一个 goroutine 取走进行消费\n如果多个 goroutine 监听同一个 channel，如果这个 channel 被关闭，则所有 goroutine 都能收到退出信号\nChannel 死锁 无缓存 Channel 只写不读 1 2 3 4 func deadlock( ) { ch := make(chan int) ch\u0026lt;-5 // 程序会一直阻塞在这里 } 无缓存 Channel 读在写后 1 2 3 4 5 6 func deadlock() { ch:=make(chan int) ch\u0026lt;-5 // 程序会一直阻塞在这里 num:=\u0026lt;-ch fmt.Println(\u0026#34;num=\u0026#34;,num) } 有缓存 Channel 写入超过缓冲区大小 1 2 3 4 5 6 func deadlock() { ch := make(chan int, 2) ch\u0026lt;-1 ch\u0026lt;-2 ch\u0026lt;-3 // 这里会发生一直阻塞的情况 } 空读 1 2 3 4 func deadlock() { ch := make(chan int) fmt.Println(\u0026lt;-ch) } 多个协程相互等待 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 func deadlock() { ch1 := make(chan int) ch2 := make(chan int) // 互相等对方造成死锁 go func() { for { select { case num := \u0026lt;-ch1: fmt.Println(\u0026#34;num=\u0026#34;, num) ch2 \u0026lt;- 100 } } }() for { select { case num := \u0026lt;-ch2: fmt.Println(\u0026#34;num=\u0026#34;, num) ch1 \u0026lt;- 300 } } } ","date":"2025-01-17T13:59:42+08:00","permalink":"https://the-oone.github.io/p/go%E5%85%AB%E8%82%A1%E4%B9%8Bchannel/","title":"Go八股之Channel"},{"content":"实现原理 Go 的 map 是一个指针，占用 8 个字节，指向 hmap 结构体，map 底层是基于哈希表+链地址法存储的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 type hmap struct { count int // 当前 map 中元素个数 flags uint8 // 写入状态标志 B uint8 // buckets 的数量（2^B 个） noverflow uint16 // 溢出 buckets 的数量 hash0 uint32 // 生成 hash 的随机数种子 buckets unsafe.Pointer // 指向 buckets 数组的指针 oldbuckets unsafe.Pointer // 扩容时，指向扩容前的 buckets 数组的指针 nevacuate uintptr // 表示扩容进度，小于此地址的 buckets 已经迁移成功 extra *mapextra // 保存溢出桶的地址 } type mapextra struct { overflow *[]*bmap // overflow 包含的是 hmap.buckets 的 overflow 的 buckets oldoverflow *[]*bma // oldoverflow 包含扩容时 hmap.oldbuckets 的 overflow 的 bucket nextOverflow *bmap // 指向空闲的 overflow bucket 的指针 } bmap 就是我们常说的 bucket，一个 bucket 里面会最多装 8 个key，这些 key 哈希结果的低 B 位是相同的。在 bucket 内，又会根据 key 计算出来的hash值的高8位（一个桶内最多有8个位置）来决定 key 到底落入哪个位置。\n当 map 的 key 和 value 均不为指针类型时，bmap 将完全不包含指针，那么垃圾回收就不用扫描 bmap。bmap 指向溢出桶的字段 overflow 是 uintptr 类型，为了防止这些溢出桶被垃圾回收，所以需要 mapextra.overflow 将它保存起来。如果 bmap 的 overflow 是 *bmap 类型，那么垃圾回收需要扫描一个个拉链表，效率明显不如直接扫描一段内存（hmap.mapextra.overflow）效率高。\n1 2 3 4 5 6 7 8 9 10 11 12 // bmap 静态结构 type bmap struct { tophash [bucketCnt]uint8 } // bmap 动态结构 type bmap struct{ tophash [8]uint8 // 存储哈希值的高 8 位，用于快速比较和查找 keys [8]keytype // 存放 key，keytype 由编译器编译时候确定 values [8]elemtype // 存放 value，elemtype 由编译器编译时候确定 overflow uintptr // 指向下一个 bmap，overflow 是 uintptr 而不是 *bmap 类型，保证 bmap 完全不含指针，是为了减少 GC，溢出桶存储到 extra 字段中 } tophash 字段不仅存储 hash(key) 的高 8 位，还会存储一些状态值，用来表明当前 bucket 状态。/为了避免 hash(key) 高 8 位值和这些状态值相等，所以当 hash(key) \u0026lt; minTopHash 时，自动将其值加上 minTopHash 作为该 key 的 tophash。\n1 2 3 4 5 6 emptyRest= 0 //表明此桶单元为空，且更高索引的单元也是空 emptyOne=1 //表明此桶单元为空 evacuatedX= 2 //用于表示扩容迁移到新桶前半段区间 evacuatedY= 3 //用于表示扩容迁移到新桶后半段区间 evacuatedEmpty = 4 //用于表示此单元已迁移 minTopHash= 5 // key的tophash值与桶状态值分割线值，小于此值的一定代表着桶单元的状态，大于此值的一定是key对应的tophash值 初始化 Map 创建一个 hmap 结构体对象 生成一个哈希因子 hash0 并赋值到 hmap 对象中（用于后续为key创建哈希值） 根据 hint=10，并根据算法规则来创建B，此时的 B=1 根据 B 去创建 bucket 并存放在数组中。当前的 Bmap 的数量为 2 B\u0026lt;4时，创建桶的个数为：$2^B$（标准桶） B≥4时，创建桶的个数为：$2^B+2^{B-4}$（标准桶+溢出桶） 扩容 Map Go map 扩容，数据迁移不是一次性迁移，而是等到访问到具体某个 bucket 时才将数据从旧 bucket 中迁移到新bucket 中。\n一次性迁移会涉及到cpu资源和内存资源的占用，在数据量较大时，会有较大的延时，影响正常业务逻辑。因此 Go 采用渐进式的数据迁移，每次最多迁移两个bucket的数据到新的buckets中（一个是当前访问key所在的bucket，然后再多迁移一个bucket） 触发时机 超过负载：map 元素个数 \u0026gt; 6.5 * bucket 数量\n1 2 3 4 5 6 7 8 9 if !h.growing() \u0026amp;\u0026amp; (overLoadFactor(h.count+1, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) { hashGrow(t, h) goto again // Growing the table invalidates everything, so try again } // 判断是否在扩容 func (h *hmap) growing() bool { return h.oldbuckets != nil } 溢出桶太多：当 bucket 小于 $2^{15}$ 且溢出桶总大于等于桶总数，则认为溢出桶过多；当 bucket 大于等于 $2^{15}$时且溢出桶总数大于等于 $2^{15}$时，即认为溢出桶太多了。\n扩容机制 双倍扩容：如果是因为超过负载扩容，新建一个 buckets 数组（大小为原先的 2 倍），然后旧的 buckets 数据搬到新的 buckets 中 等量扩容：如果是因为溢出桶太多，buckets 数量维持不变，重新做一遍类似双倍扩容的搬迁操作， 把松散的键值对重新排列一次，使得同一个bucket中的key排列地更紧密，提高buckets利用 率，进而保证更快的存取。 遍历 Map 使用 range 多次遍历 map 时输出的 key 和 value 的顺序可能不同。这是 Go 语言的设计者们有意为之，旨在提示开发者们，Go 底层实现并不保证 map 遍历顺序稳定，请大家不要依赖 range 遍历结果顺序。\n主要原因有一下两点：\nmap在遍历时，并不是从固定的0号bucket开始遍历的，每次遍历，都会从一个随机值序号的bucket，再从其中随机的cell开始遍历 map遍历时，是按序遍历bucket，同时按需遍历bucket中和其overflow bucket中的cell。但是map在扩容后，会发生key的搬迁，这造成原来落在一个bucket中的key，搬迁后，有可能会落到其他bucket中了，从这个角度看，遍历map的结果就不可能是按照原来的顺序了 map 本身是无序的，且遍历时顺序还会被随机化，如果想顺序遍历 map，需要对 map key 先排序，再按照 key 的顺序遍历 map。\n查找 Map Go 语言中读取 map 有两种语法：带 comma 和 不带 comma。当要查询的 key 不在 map 里，带 comma 的用法会返回一个 bool 型变量提示 key 是否在 map 中；而不带 comma 的语句则会返回一个 value 类型的零值。如果 value 是 int 型就会返回 0，如果 value 是 string 类型，就会返回空字符串。\n1 2 3 4 5 6 7 8 9 // 不带 comma 用法 value := m[\u0026#34;name\u0026#34;] fmt.Printf(\u0026#34;value:%s\u0026#34;, value) // 带 comma 用法 value, ok := m[\u0026#34;name\u0026#34;] if ok { fmt.Printf(\u0026#34;value:%s\u0026#34;, value) } 整个流程如下：\n写保护监测：函数首先会检查标志位 flags。如果 flags 的写标志位此时被置 1 了，说明有其他协程在执行写操作，进而导致程序 panic（这也说明了 map 不是线程安全的）； 计算hash值：hash:=t.hasher(key,uintptr(h.hash0))， 不同类型的key会有不同的hash函数 找到hash对应的bucket：hash 的低 B 个 bit 位，用来定位 key 所存放的bucket。如果当前正在扩容中，并且定位到的旧bucket数据还未完成迁移，则使用旧的bucket（扩容前的bucket） 遍历bucket查找：利用哈希值的高 8 个 bit 位快速判断 key 是否已在当前 bucket 中（如果不在的话，需要去 bucket 的 overflow 中查找） 返回key对应的指针：如果通过上面的步骤找到了key对应的槽位下标 i，根据此得到对应 value 的值 map 冲突解决方案 链地址法 开放寻址法 线性探测法 Go map采用链地址法解决冲突，具体就是插入key到map中时，当key定位的桶填满8个元素后（这里的单元就是桶，不是元素），将会创建一个溢出桶，并且将溢出桶插入当前桶所在链表尾部。\nmap 的负载因子 $负载因子=\\frac{哈希表中存储元素}{桶数量}$，其是衡量当前哈希表中空间占用率的核心指标。\nGo Map 的负载因子是 6.5，原因就是官方测试这个数值负载因子的性能较好，具体可看测试：\n负载因子 溢出率 耗费字节数/kv 对 查找平均个数（k存在） 查找平均个数（k不存在） 4.00 2.13 20.77 3.00 4.00 4.50 4.05 17.30 3.25 4.50 5.00 6.85 14.77 3.50 5.00 5.50 10.55 12.94 3.75 5.50 6.00 15.27 11.67 4.00 6.00 6.50 20.90 10.79 4.25 6.50 7.00 27.14 10.15 4.50 7.00 7.50 34.03 9.73 4.75 7.50 8.00 41.10 9.40 5.00 8.00 Map 和 sync.Map Go 语言的 sync.Map 支持并发读写\n1 2 3 4 5 6 type Map struct { mu Mutex read atomic.Value // readOnly dirty map[interface{}]*entry misses int } map 在单个 goroutine 上的读写性能会很好，因为他在读写时没有额外的同步开销，但是他并不是并发安全的，如果多个 goroutine 同时读写一个 map 会导致数据竞争 sync.Map 通常在并发读写时性能较好，在多 goroutine 场景下会更加安全，适合读多写少场景（写多场景下会导致 read map 缓存失效，性能下降） ","date":"2025-01-16T13:42:27+08:00","permalink":"https://the-oone.github.io/p/go%E5%85%AB%E8%82%A1%E4%B9%8Bmap/","title":"Go八股之Map"},{"content":"Go 的内存分配机制 Go语言内置运行时（就是runtime），抛弃了传统的内存分配方式，改为自主管理。这样可以自主地实现更好的内存使用模式，比如内存池、预分配等等。这样，不会每次内存分配都需要进行系统调用。\n设计思想 内存分配算法采用TCMalloc算法，每个线程都会自行维护一个独立的内存池，进行内存分配时优先从该内存池中分配，当内存池不足时才会向加锁向全局内存池申请，减少系统调用并且避免不同线程对全局内存池的锁竞争 把内存切分的非常的细小，分为多级管理，以降低锁的粒度 回收对象内存时，并没有将其真正释放掉，只是放回预先分配的大块内存中，以便复用。只有内存闲置过多的时候，才会尝试归还部分内存给操作系统，降低整体开销 分配组件 Go 的内存管理组件主要有：mspan、mcache、mcentral、mheap\nmspan：内存管理单元 mspan是内存管理的基本单元，该结构体中包含next和 prev两个字段，它们分别指向了前一个和后一个mspan，每个mspan都管理npages个大小为8KB的页，一个span是由多个page组成的，这里的页不是操作系统中的内存页，它们是操作系统内存页的整数倍。\n1 2 3 4 5 6 7 8 9 type mspan struct { next *mspan //后指针 prev *mspan //前指针 startAddr uintptr //管理页的起始地址，指向page npages uintptr //页数 spanclass spanClass //规格，字节数 ... } type spanclass uint8 mcache：线程缓存 mcache 管理线程在本地缓存的 mspan，每个 goroutine 绑定的P都有一个 mcache 字段\n1 2 3 4 5 6 type mcache struct{ alloc [numSpanClasses]*mspan } _NumSizeClasses=68 numSpanClassed=_NumSizeClassed\u0026lt;\u0026lt;1 mcache 用 Span Classes 作为索引管理多个用于分配的 mspan，它包含所有规格的 mspan。它是_NumSizeClasses 的2倍，也就是 68*2=136，其中 *2 是将spanClass分成了有指针和没有指针两种,方便与垃圾回收。对于每种规格，有2个mspan，一个mspan不包含指针，另一个mspan则包含指针。对于无指针对象的mspan在进行垃圾回收的时候无需进一步扫描它是否引用了其他活跃的对象。\nmcache在初始化的时候是没有任何mspan资源的，在使用过程中会动态地从mcentral申请，之后会缓存下来。当对象小于等于32KB大小时，使用mcache的相应规格的mspan进行分配。\nmcentral：中心缓存 mcentral管理全局的mspan供所有线程使用，全局mheap变量包含central字段，每个 mcentral 结构都维护在mheap结构内\n1 2 3 4 5 6 type mcentral struct { spanclass spanClass // 指当前规格大小 partial [2]spanSet // 有空闲object的mspan列表 full [2]spanSet // 没有空闲object的mspan列表 } 每个mcentral管理一种spanClass的mspan，并将有空闲空间和没有空闲空间的mspan分开管理。partial和 full的数据类型为spanSet，表示 mspans集，可以通过pop、push来获得mspans\n1 2 3 4 5 6 7 8 type spanSet struct { spineLock mutex spine unsafe.Pointer // 指向[]span的指针 spineLen uintptr // Spine array length, accessed atomically spineCap uintptr // Spine array cap, accessed under lock index headTailIndex // 前32位是头指针，后32位是尾指针 } 简单说下mcache从mcentral获取和归还mspan的流程：\n获取； 加锁，从partial链表找到一个可用的mspan；并将其从partial链表删除；将取出的mspan加入到full链表；将mspan返回给工作线程，解锁。 归还； 加锁，将mspan从full链表删除；将mspan加入到partial链表，解锁。 mheap：页堆 mheap管理Go的所有动态分配内存，可以认为是Go程序持有的整个堆空间，全局唯一\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 var mheap_ mheap type mheap struct { lock mutex // 全局锁 pages pageAlloc // 页面分配的数据结构 allspans []*mspan // 所有通过 mheap_ 申请的mspans // 堆 arenas [1 \u0026lt;\u0026lt; arenaL1Bits]*[1 \u0026lt;\u0026lt; arenaL2Bits]*heapArena // 所有中心缓存mcentral central [numSpanClasses]struct { mcentral mcentral pad [cpu.CacheLinePadSize - unsafe.Sizeof(mcentral{})%cpu.CacheLinePadSize]byte } ... } 所有mcentral的集合则是存放于mheap中的。mheap里的arena 区域是堆内存的抽象，运行时会将 8KB 看做一页，这些内存页中存储了所有在堆上初始化的对象。运行时使用二维的 runtime.heapArena 数组管理所有的内存，每个 runtime.heapArena 都会管理 64MB 的内存。\n当申请内存时，依次经过 mcache 和 mcentral 都没有可用合适规格的大小内存，这时候会向 mheap 申请一块内存。然后按指定规格划分为一些列表，并将其添加到相同规格大小的 mcentral 的 非空闲列表 后面\n分配流程 首先通过计算使用的大小规格 然后使用mcache中对应大小规格的块分配。 如果mcentral中没有可用的块，则向mheap申请，并根据算法找到最合适的mspan。 如果申请到的mspan 超出申请大小，将会根据需求进行切分，以返回用户所需的页数。剩余的页构成一个新的 mspan 放回 mheap 的空闲列表。 如果 mheap 中没有可用 span，则向操作系统申请一系列新的页（最小 1MB） 内存逃逸 内存逃逸指的是在函数内部分配的变量在函数结束后仍然被其他部分引用，导致其生命周期延长到函数外部。这种情况下，变量将不再局限于函数栈中，而是被分配到堆上。内存逃逸会导致额外的内存分配和垃圾回收的开销，影响程序的性能。\n指针逃逸 在函数中创建了一个对象，返回了这个对象的指针。这种情况下，函数虽然退出了，但是因为指针的存在，对象的内存不能随着函数结束而回收，因此只能分配在堆上。\n1 2 3 4 5 6 7 8 9 10 package main func add(x, y float64) *float64 { res := x + y return \u0026amp;res } func main() { add(1, 1.0) } 这段代码中 res 变量发生了逃逸。使用 go build -gcflags=-m 指令可以看到：\n1 2 3 4 5 # command-line-arguments ./test6.go:3:6: can inline add ./test6.go:8:6: can inline main ./test6.go:9:5: inlining call to add ./test6.go:4:2: moved to heap: res 栈空间不足 当栈空间足够时，不会发生逃逸，但是当变量过大时，已经完全超过栈空间的大小时，将会发生逃逸到堆上分配内存。局部变量s占用内存过大，编译器会将其分配到堆上\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 package main import ( \u0026#34;math/rand\u0026#34; ) func f1() { nums := make([]int, 8192) // 64KB for i := 0; i \u0026lt; 8191; i++ { nums[i] = rand.Int() } } func f2() { nums := make([]int, 8193) // 64KB + 8B for i := 0; i \u0026lt; 8192; i++ { nums[i] = rand.Int() } } func main() { f1() f2() } 上述代码中，f1 函数发生未内存逃逸，f2 函数发生内存逃逸。（博主环境为 Windows 10，Go 1.23.0）\n1 2 3 # command-line-arguments ./test7.go:8:14: make([]int, 8192) does not escape ./test7.go:15:14: make([]int, 8193) escapes to heap 变量大小不确定 编译期间无法确定slice的长度，这种情况为了保证内存的安全，编译器也会触发逃逸，在堆上进行分配内存。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 package main import \u0026#34;math/rand\u0026#34; func f(n int) { nums := make([]int, n) for i := 0; i \u0026lt; n; i++ { nums[i] = rand.Int() } } func main() { f(1) } 1 2 3 # command-line-arguments ./test8.go:12:6: can inline main ./test8.go:6:14: make([]int, n) escapes to heap interface{} 动态类型逃逸 1 2 3 4 5 6 7 package main import \u0026#34;fmt\u0026#34; func main() { fmt.Println(\u0026#34;hello world\u0026#34;) } hello world 字符串作为实参传递给 fmt.Println()，但是因为 fmt.Println() 的参数类型定义为 interface{} 因此也会发生内存逃逸。\n1 2 3 4 5 # command-line-arguments ./test9.go:5:6: can inline main ./test9.go:7:13: inlining call to fmt.Println ./test9.go:7:13: ... argument does not escape ./test9.go:7:14: \u0026#34;hello world\u0026#34; escapes to heap 闭包引用对象 一个函数和对其周围状态的引用捆绑在一起，这样的组合就是闭包。也就是说，闭包让你可以在一个内层函数中访问到其外层函数的作用域。\n1 2 3 4 5 6 7 8 9 10 11 12 13 package main func test() func() int { var i int = 1 return func() int { i++ return i } } func main() { test() } test() 返回值是一个闭包函数，该闭包函数访问外部变量 n，n 会一直存在直到 test() 函数被销毁。\n1 2 3 4 5 6 7 8 # command-line-arguments ./test10.go:3:6: can inline test ./test10.go:5:9: can inline test.func1 ./test10.go:11:6: can inline main ./test10.go:12:6: inlining call to test ./test10.go:4:6: moved to heap: i ./test10.go:5:9: func literal escapes to heap ./test10.go:12:6: func literal does not escape 小结 栈上分配内存比在堆中分配内存效率更高 栈上分配的内存不需要 GC 处理，而堆需要 逃逸分析目的是决定内分配地址是栈还是堆 逃逸分析在编译阶段完成 因为无论变量的大小，只要是指针变量都会在堆上分配，所以对于小变量我们还是使用传值效率更高一点。\nGo 内存对齐机制 内存对齐 为了能让CPU可以更快的存取到各个字段，Go编译器会帮你把struct结构体做数据的对齐。所谓的数据对齐，是指内存地址是所存储数据大小（按字节为单位）的整数倍，以便CPU可以一次将该数据从内存中读取出来。 编译器通过在结构体的各个字段之间填充一些空白已达到对齐的目的。\n对齐系数 不同硬件平台占用的大小和对齐值都可能是不一样的，32位系统对齐系数是4，64位系统对齐系数是8。\n不同类型的对齐系数也可能不一样，使用Go 语言中的unsafe.Alignof函数可以返回相应类型的对齐系数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;unsafe\u0026#34; ) func main() { fmt.Printf(\u0026#34;bool alignof is %d\\n\u0026#34;, unsafe.Alignof(bool(true))) // bool alignof is 1 fmt.Printf(\u0026#34;string alignof is %d\\n\u0026#34;, unsafe.Alignof(string(\u0026#34;a\u0026#34;))) // string alignof is 8 fmt.Printf(\u0026#34;int8 alignof is %d\\n\u0026#34;, unsafe.Alignof(int8(0))) // int8 alignof is 1 fmt.Printf(\u0026#34;int16 alignof is %d\\n\u0026#34;, unsafe.Alignof(int16(0))) // int16 alignof is 2 fmt.Printf(\u0026#34;int32 alignof is %d\\n\u0026#34;, unsafe.Alignof(int32(0))) // int32 alignof is 4 fmt.Printf(\u0026#34;int64 alignof is %d\\n\u0026#34;, unsafe.Alignof(int64(0))) // int64 alignof is 8 fmt.Printf(\u0026#34;float32 alignof is %f\\n\u0026#34;, unsafe.Alignof(float32(0))) // float32 alignof is 4 fmt.Printf(\u0026#34;float alignof is %d\\n\u0026#34;, unsafe.Alignof(float64(0))) // float alignof is 8 } 对齐原则 结构体变量中成员的偏移量必须是成员变量大小和成员对齐系数两者最小值的整数倍 整个结构体的地址必须是最大字节和编译器默认对齐系数两者最小值的整数倍（结构体的内存占用是1/4/8/16 byte\u0026hellip;） struct{}放在结构体中间不进行对齐，放在结构体最后一个字段则要根据最大字节和编译器默认对齐系数两者最小值来进行字段对齐 优势 提高可移植性，有些CPU可以访问任意地址上的任意数据，而有些CPU只能在特定地址访问数据，因此不同硬件平台具有差异性，这样的代码就不具有移植性，如果在编译时，将分配的内存进行对齐，这就具有平台可以移植性了\n提高内存的访问效率，32位CPU下一次可以从内存中读取32位（4个字节）的数据，64位CPU下一次可以从内存中读取64位（8个字节）的数据，这个长度也称为CPU的字长。CPU一次可以读取1个字长的数据到内存中，如果所需要读取的数据正好跨了1个字长，那就得花两个CPU周期的时间去读取了。因此在内存中存放数据时进行对齐，可以提高内存访问效率。\n劣势 存在内存空间的浪费 make 和 new 的异同 make new make 仅用来分配及初始化类型为 slice、map、chan 的数据。 new 可分配任意类型的数据，根据传入的类型申请一块内存，返回指向这块内存的指针，即类型 *Type。 make函数返回的是slice、map、chan类型本身 new函数返回一个指向该类型内存地址的指针 ","date":"2025-01-15T14:44:36+08:00","permalink":"https://the-oone.github.io/p/go%E5%85%AB%E8%82%A1%E4%B9%8B%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D/","title":"Go八股之内存分配"},{"content":"什么是 Slice 切片是基于数组实现的，底层是数组，可以理解为对底层数组的抽象\n数据结构 1 2 3 4 5 type slice struct{ array unsafe.Pointer // 指向底层数组的指针，占 8 字节 len int // 切片长度，占 8 字节 cap int // 切片容量，占 8 字节 } 初始化 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 func main() { // 直接声明 var s1 []int // 使用字面量 s2 := []int{1, 2, 5} // 使用 make s3 := make([]int, 1, 4) // 指定长度为1.容量为4 s4 := make([]int, 1) // 指定长度为 1，容量默认为1 // 从其他切片或数组中截取 arr := [5]int{1, 2, 3, 4, 5} s5 := arr[1:3] } 基于切片和数组创建的切片会和原数组或切片共享底层空间，修改切片会影响原数组或切片\n扩容 1 2 3 4 5 6 7 func main() { s := make([]int, 0) s = append(s, 1, 2) // 追加元素 fmt.Println(s) // [1 2] s = append(s, []int{3, 4}...) // 追加切片 fmt.Println(s) // [1 2 3 4] } V1.18 版本之前 如果所需容量大于原容量的二倍，则新容量为所需容量。 如果原slice容量小于1024，则新slice容量将扩大为原来的二倍。 如果原slice容量大于或等于1024，则新slice容量将扩大为原来的1.25倍。 V1.18 版本 如果所需容量大于原容量的二倍，则新容量为所需容量。 如果原slice容量小于256，则新slice容量将扩大为原来的二倍。 如果原容量大于或等于256，进入一个循环，每次容量增加（旧容量 + 3 * threshold）/ 4 。 而每次扩容后，切片将会开辟一块新的空间，将原切片中的数据拷贝到新地址中，而原先的那片空间就会被抛弃（仅限于没有其他指针指向原先的老空间）\nArray 和 Slice 的区别 数组是固定长度，其大小在定义阶段就必须确定，函数传递中数组传递值。它的物理空间连续，性能相对较高，适合存储已知数量元素的场景。\n切片是动态的序列，其是一个引用类型，指向了底层数组，大小可变，函数传递中传递引用。性能较低，但是灵活性高，适合数量未知或者频繁需要增删的场景\nSlice 线程安全嘛 slice 底层结构并没有使用加锁等方式，不支持并发读写，所以并不是线程安全的，使用多个 goroutine 对类型为 slice 的变量进行操作，每次输出的值大概率都不会一样，与预期值不一致; slice在并发执行中不会报错，但是数据会丢失\nSlice 深拷贝和浅拷贝 深拷贝 拷贝的是数据本身，创造一个新对象，新创建的对象与原对象不共享内存，新创建的对象在内存中开辟一个新的内存地址，新对象值修改时不会影响原对象值\n1 2 3 4 5 6 7 8 9 10 11 12 func main() { s1 := []int{1, 2, 3, 4, 5} s2 := make([]int, 5, 5) fmt.Printf(\u0026#34;s1: %v, %p\\n\u0026#34;, s1, s1) // s1: [1 2 3 4 5], 0xc00000e420 copy(s2, s1) fmt.Printf(\u0026#34;s2: %v, %p\\n\u0026#34;, s2, s2) // s2: [1 2 3 4 5], 0xc00000e450 s3 := make([]int, 0, 5) for _, v := range s1 { s3 = append(s3, v) } fmt.Printf(\u0026#34;s3: %v, %p\\n\u0026#34;, s3, s3) // s3: [1 2 3 4 5], 0xc00000e480 } 浅拷贝 拷贝的是数据地址，只复制指向的对象的指针，此时新对象和老对象指向的内存地址是一样的，新对象值修改时老对象也会变化\n1 2 3 4 5 6 func main() { s1 := []int{1, 2, 3, 4, 5} fmt.Printf(\u0026#34;s1: %v, %p\\n\u0026#34;, s1, s1) // s1: [1 2 3 4 5], 0xc00000e420 s2 := s1 fmt.Printf(\u0026#34;s2: %v, %p\\n\u0026#34;, s2, s2) // s2: [1 2 3 4 5], 0xc00000e420 } nil slice 和 空slilce nil slice 表示未初始化的切片，不分配任何内存，其值为 nil\n空 slice 表示已初始化但长度为零，分配内存\n二者并不相等，但是对这两个都可以进行 append 操作\n1 2 3 4 5 6 7 8 9 10 11 12 func main() { var a []int // nil slice b := []int{} // empty slice fmt.Println(a == nil) // true fmt.Println(b == nil) // false fmt.Println(len(a), cap(a)) // 0 0 fmt.Println(len(b), cap(b)) // 0 0 a = append(a, 1) // a现在是包含一个元素的切片 [1] fmt.Println(a, len(a), cap(a)) // [1] 1 1 b = append(b, 1) // b现在也是包含一个元素的切片 [1] fmt.Println(a, len(a), cap(a)) // [1] 1 1 } ","date":"2025-01-15T13:12:33+08:00","permalink":"https://the-oone.github.io/p/go%E5%85%AB%E8%82%A1%E4%B9%8Bslice/","title":"Go八股之Slice"},{"content":"Redis 为什么需要持久化 RDB（Redis Database） RDB 持久化以指定的时间间隔对数据集执行时间点快照（实际上就是记录某一个时间节点的内存数据）。\n配置操作 Redis 7.4.2 默认 RDB 参数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # 1p/1h 或 100p/5m 或 10000p/60s save 3600 1 300 100 60 10000 # RDB 快照保存文件名 dbfilename dump.rdb # RDB 快照保存目录 dir ./ # 在快照写入失败时是否停止写请求 stop-writes-on-bgsave-error yes # 是否开启 RDB 压缩（LZF压缩算法） rdbcompression yes # 是否开启 RDB 数据校验（CRC64算法） rdbchecksum yes # 是否删除未启用持久性的实例中复制使用的 RDB 文件 rdb-del-sync-files no 默认情况下，Redis 会将数据集的快照保存在磁盘上一个名为 dump.rdb 的二进制文件中。 你也可以手动调用 SAVE 或 BGSAVE 命令。\n执行 save 命令，就会在主线程生成 RDB 文件，由于和执行操作命令在同一个线程，所以如果写入 RDB 文件的时间太长，会阻塞主线程。线上禁止使用 执行了 bgsave 命令，会创建一个子进程来生成 RDB 文件，这样可以避免主线程的阻塞 执行 flushall/flushdb 命令也会产生 .rdb 文件，但是该文件中没有任何数据（因为他是在清盘之后才保存的）。在恢复数据时，一定要将服务和备份分机隔离（防止备份的 .rdb 文件被覆盖）。\n触发时机 配置文件中默认的快照配置 手动 sava/bgsave 命令 执行 flushall/flushdb 命令 执行 shutdown 且没有设置 AOF 持久化 主从复制，主节点自动触发 优势 适合大规模的数据恢复 按照业务定时备份 对数据完整性和一致性要求不高 RDB 文件在内存中加载速度比 AOF 快得多 劣势 RDB 会丢失备份间隔时间内的所有数据，也就是说距离上一次备份期间内的所有数据都会被丢失 RDB 是全量快照，每次执行都会把所有的数据记录到磁盘中，频繁的磁盘 I/O 可能影响服务器性能 RDB 依赖主进程的 fork，在极端形况下内存占用会变为原先的 2 倍。 执行 RDB 快照时能否修改数据 可以，使用写时复制技术。\n执行 bgsave 命令时，通过 fork() 创建子进程，因此父进程、子进程共享同一片内存数据（两份页表，一份物理内存）。只有当发生数据修改时，才会复制一份新的物理内存（注意此时子进程会将旧的物理内存写入 RDB 文件，而主进程会在新的物理内存中修改数据）。这样就可以避免主线程阻塞。\nAOF（Append Only File） AOF 持久性记录服务器收到的每个写入操作。 这些操作可以在服务器启动时再次重放，重建原始数据集。 命令记录格式与 Redis 协议本身相同。\n配置操作 Redis 7.4.2 默认 AOF 参数\n1 2 3 4 5 6 7 8 9 10 11 12 13 # AOF 默认关闭 appendonly no # AOF 文件名 appendfilename \u0026#34;appendonly.aof\u0026#34; # AOF 保存目录 appenddirname \u0026#34;appendonlydir\u0026#34; # 回写策略（三种，默认 everysec） # appendfsync always appendfsync everysec # appendfsync no 默认情况下，Redis 会将记录到的命令文件保存在磁盘上一个名为 appendonly.aof 的文件中。 Redis 6 之前只有一个 AOF 文件。Redis 7 之后有三个文件（合并在一个文件中）：\nappendonly.aof.1.base.rdb：基础 AOF，最多只有一个，一般由子进程通过重写产生 appendonly.aof.1.incr.aof：增量 AOF，可能存在多个，一般会在 AOF 重写时创建 历史 AOF，每次 AOF 重写完成时，之前的基础 AOF 和增量 AOF 都会编程历史 AOF。Redis 配置里没有，因为它会被自动删除 appendonly.aof.manifest：跟踪管理 AOF 文件 工作流程 Client 向 Redis 发送操作命令 这些命令首先进入 AOF 缓冲区保存（避免频繁的磁盘 I/O 操作） AOF 根据写回策略将缓冲区命令写入磁盘中 为了 AOF 文件的膨胀，会进行 AOF 重写压缩文件 Redis 会在服务启动时加载磁盘中的 AOF 文件再次执行这些命令 执行优势 Redis 是先执行写操作命令后，才将该命令记录到 AOF 日志里的，这么做其实有两个好处。\n避免额外的检查开销，因为能执行的命令必然是正确的命令 不会阻塞当前写操作命令的执行，因为只有写命令直接成功后才会记录 执行劣势 当 Redis 执行命令后，记录命令前，这个时刻 Redis 服务宕机，那么这个数据就会有丢失的风险 由于 Redis 执行命令和 AOF 写入这两个操作均是在一个线程中完成，那么可能导致下一个命令阻塞 写回策略 上图中第二步和第三步可以再细化为以下几步：\nRedis 执行完写命令后，将该命令追加到 server.aoof_buf 缓冲区中 通过调用系统函数 write()，将缓冲区内数据写入到 AOF 文件中，此时数据并没有写入到硬盘，而是拷贝到了内核缓冲区 page cache 内核缓冲区将数据写入硬盘 Redis 提供了三种写回策略\nAlways 策略含义：每次写命令执行完后，将 AOF 写回硬盘 实际操作：每次写命令执行完之后立刻执行 fsync() 函数 Everysec 策略含义：每次写命令执行完后，先将其写入 AOF 缓冲区，之后每隔一秒将缓冲区写入磁盘 实际操作：每次写命令执行完之后，会创建一个异步进程执行 fsync() 函数 No 策略含义：每次写命令执行完后，先将其写入 AOF 缓冲区，之后将缓冲区写入磁盘（由操作系统决定间隔时间） 实际操作：永远不执行 fsync() 函数 小结 写回策略 写回时机 优点 缺点 Always 同步写回 可靠性高 性能开销大 Everysec 每秒写回 性能、可靠性均衡 宕机丢失 1 秒内数据 No 由操作系统决定 性能高 宕机丢失数据多 重写机制 当 AOF 文件的大小（默认64MB）超过所设定的阈值后，Redis 启动 重写机制。由于重写操作十分耗时，所以该过程是由子进程 bgrewriteaof 完成的，有以下两点好处\n重写期间避免阻塞主进程 子进程带有主进程的数据副本，如果父子进程任何一方修改内存会触发写时复制机制，确保数据安全。 触发重写机制后，主进程就会创建重写的 AOF 子进程，此时父子进程共享物理内存，重写子进程只会对该内存读取，重写 AOF 子进程会读取数据库里的所有数据，并逐一把内存数据的键值对转换为一条命令，再将命令记录到重回日志（新的 AOF 文件）。\n子进程完成 AOF 重写工作后，会向主进程发送一条异步信号。主进程收到信号后首先将 AOF 缓冲区中所有内容追加到新的 AOF 文件中，然后将新的 AOF 文件改名，覆盖掉旧的 AOF 文件。\n","date":"2025-01-14T21:04:32+08:00","permalink":"https://the-oone.github.io/p/redis%E6%8C%81%E4%B9%85%E5%8C%96/","title":"Redis持久化"},{"content":"什么是 GC 垃圾回收（Garbage Collection，GC）是一种自动内存管理机制。\n现代高级编程语言管理内存有两种方式：\n手动：C/C++，Rust等，需要主动申请或者释放内存 自动：Java，Golang等，有内存分配器和垃圾收集器自动分配和回收内存 程序中会使用两种内存：\n堆内存：程序共享的内存，由 GC 进行回收 栈内存：线程专用的内存，存储函数的参数值、局部变量等，由操作系统自动分配释放 Go 的垃圾回收 GC 相关术语 STW：全称 stop the word，GC 期间某个阶段会停止所有的赋值器，中断程序逻辑，以确定引用关系。 root 对象：根对象是指赋值器不需要通过其他对象就可以直接访问到的对象 GC V1.3 1.3 版本 Go 使用标记-清除作为垃圾回收算法：\n开启STW，停止程序的运行 从根节点遍历，标记找出的所有可达对象 清理未标记的对象 继续运行程序 重复循环上述 1-4 步，直到 process 程序生命周期结束。标记清除法的最大弊端就是在整个GC期间需要STW，将整个程序暂停。因为如果不进行STW的话，会出现已经被标记的对象A，引用了新的未被标记的对象B，但由于对象A已经标记过了，不会再重新扫描A对B的可达性，从而将B对象当做垃圾回收掉。\nGC V1.5 1.5 版本使用标记-清除算法，结合三色标记，插入写屏障：\n创建白、灰、黑三个集合 将所有对象先放入白色集合中 遍历所有 root 对象，把遍历到的对象从白色集合放入灰色集合（这里放入灰色集合的都是根节点直接可达的对象） 遍历灰色集合，将灰色对象直接可达的对象从白色集合放入灰色集合，自身标记为黑色 重复第四步，直至灰色集合中没有任何对象 回收白色集合内的所有对象 对于上述的算法来讲,仍然需要依赖STW的。因为如果不暂停程序, 程序的逻辑改变对象引用关系, 这种动作如果在标记阶段做了修改，会影响标记结果的正确性。\n在三色标记法过程中对象丢失需要同时满足两个条件：\n条件一：白色对象被黑色对象引用 条件二：灰色对象和白色对象之间的可达关系遭到破坏 Go 团队提出两个解决方案\n强三色不变式：不允许黑色对象引用白色对象，破坏条件一 弱三色不变式：黑色对象可以引用白色对象，但是白色对象的上游必须存在灰色对象，破坏条件二 Go 团队基于上述不变式提出两种实现机制：\n插入写屏障（满足强三色不变式） 规则：当一个对象引用另一个对象时，将另一个对象标记为灰色 劣势：无法管理栈操作，需要 STW 重新扫描栈 删除写屏障（满足弱三色不变式） 规则：在删除引用时，如果被删除引用的对象自身为灰色或者白色，那么会标记为灰色 劣势：冗余扫描成本高，回收精度低 GC V1.8 1.8 版本使用标记-清除算法，结合三色标记法和混合写屏障\nGC 开始将栈上的所有可达对象均标记为黑色 GC 期间，任何在栈上创建的新对象，均为黑色 堆上被删除对象标记为灰色 堆上被添加的对象标记为灰色 GC 的触发时间 主动触发：调用 runtime.GC() 方法 被动触发： 定时触发，该触发条件由 runtime.forcegcperiod 变量控制，默认为 2 分 钟。当超过两分钟没有产生任何 GC 时，触发 GC 根据内存分配阈值触发，该触发条件由环境变量 GOGC 控制，默认值为100（100%），当前堆内存占用是上次 GC 结束后占用内存的 2 倍时，触发 GC GC 调优 控制内存分配的速度，限制Goroutine的数量，提高赋值器mutator的CPU利用率(降低GC的CPU利用率) 少量使用+连接string slice提前分配足够的内存来降低扩容带来的拷贝 避免map key对象过多，导致扫描时间增加 变量复用，减少对象分配，例如使用sync.Pool来复用需要频繁创建临时对象，使用全局变量 增大GOGC的值，降低GC的运行频率 ","date":"2025-01-14T13:19:36+08:00","permalink":"https://the-oone.github.io/p/go%E5%85%AB%E8%82%A1%E4%B9%8Bgc/","title":"Go八股之GC"},{"content":"历史背景 含义 缺点 进程时代 一个程序就是一个进程，所有进程严格按照时间执行 进程阻塞十分损耗性能、只能串行执行任务 线程时代 一个进程阻塞，可以切换到其他进程 上下文切换成本高、协程内存占用较高 协程时代 协程绑定线程，CPU 调度线程执行 实现复杂，协程和线程的绑定依赖调度器算法 GMP 调度模型是什么 G：Goroutine，是 Go 的用户级线程，每个 go 关键字都会创建一个 Goroutine。其数量理论上只受内存大小影响。\nM：Machine，Go 对操作系统线程的封装，M在绑定有效的 P 后，进入一个调度循环，而调度循环的机制大致是从 P 的本地运行队列以及全局队列中获取 G，切换到 G 的执行栈上并执行 G 的函数，调用 goexit 做清理工作并回到 M，如此反复。M 并不保留 G 状态，这是 G 可以跨 M 调度的基础。M的数量有限制，默认数量限制是 10000，可以通过 debug.SetMaxThreads() 方法进行设置，如果有M空闲，那么就会回收或者睡眠。\nP：Processor，虚拟处理器，M执行G所需要的资源和上下文，只有将 P 和 M 绑定，才能让 P 的 runq 中的 G 真正运行起来。P的数量受本机的CPU核数影响，可通过环境变量$GOMAXPROCS或在runtime.GOMAXPROCS()来设置，默认为CPU核心数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 //src/runtime/runtime2.go type g struct { goid int64 // 唯一的goroutine的ID sched gobuf // goroutine切换时，用于保存g的上下文 stack stack // 栈 gopc // pc of go statement that created this goroutine startpc uintptr // pc of goroutine function ... } type p struct { lock mutex id int32 status uint32 // one of pidle/prunning/... // Queue of runnable goroutines. Accessed without lock. runqhead uint32 // 本地队列队头 runqtail uint32 // 本地队列队尾 runq [256]guintptr // 本地队列，大小256的数组，数组往往会被都读入到缓存中，对缓存友好，效率较高 runnext guintptr // 下一个优先执行的goroutine（一定是最后生产出来的)，为了实现局部性原理，runnext中的G永远会被最先调度执行 ... } type m struct { g0 *g // 每个M都有一个自己的G0，不指向任何可执行的函数，在调度或系统调用时，M会切换到G0，使用G0的栈空间来调度 curg *g // 当前正在执行的G ... } type schedt struct { ... runq gQueue // 全局队列，链表（长度无限制） runqsize int32 // 全局队列长度 ... } Go 调度原理 调度对象 G 的来源 P 的 runnext（1 个 G） P 的本地队列（数组，最多 256 个 G） 全局 G 队列（链表，G 数量无限制） 网络轮询器（存放网络调用阻塞的 G） P 的来源 全局 P 队列（数组，GOMAXPROCS个P） M 的来源 休眠线程队列（未绑定 P，长时间休眠会等待GC回收销毁） 运行线程（绑定 P，指向 P 中的 G） 自旋线程（绑定 P，指向 M 的 G0） Goroutine 调度流程 上图是一个完整调度流程：\n通过 go func() 创建一个 G 创建的 G 优先保存到本地队列 P，若本地 P 已满则进去全局队列 唤醒或者新建 M 执行任务，进入调度循环（4，5，6) M 依次会从本地队列 P，全局队列，其他本地队列 P 获取 G M 调度和执行 G 如果 M 在执行 G 的过程发生系统调用阻塞（同步），会阻塞 G 和 M（操作系统限制），此时 P 会和当前 M 解绑，并寻找新的 M，如果没有空闲的 M 就会新建一个 M ，接管正在阻塞G所属的P，接着继续执行 P中其余的G，这种阻塞后释放P的方式称之为hand off。当系统调用结束后，这个G会尝试获取一个空闲的P执行，优先获取之前绑定的P，并放入到这个P的本地队列，如果获取不到P，那么这个线程M变成休眠状态，加入到空闲线程中，然后这个G会被放入到全局队列中。 如果M在执行G的过程发生网络IO等操作阻塞时（异步），阻塞G，不会阻塞M。M会寻找P中其它可执行的G继续执行，G会被网络轮询器network poller 接手，当阻塞的G恢复后，G1从network poller 被移回到P的 LRQ 中，重新进入可执行状态。异步情况下，通过调度，Go scheduler 成功地将 I/O 的任务转变成了 CPU 任务，或者说将内核级别的线程切换转变成了用户级别的 goroutine 切换，大大提高了效率。 M 执行完 G 后清理现场，重新进入调度循环（将 M 上运⾏的goroutine切换为G0，G0负责调度时协程的切换） 调度器生命周期 M0：M0 是启动程序后的编号为 0 的主线程，这个 M 对应的实例会在全局变量 runtime.m0 中，不需要在 heap 上分配，M0 负责执行初始化操作和启动第一个 G， 在之后 M0 就和其他的 M 一样了。 G0：G0 是每次启动一个 M 都会第一个创建的 gourtine，G0 仅用于负责调度的 G，G0 不指向任何可执行的函数，每个 M 都会有一个自己的 G0。在调度或系统调用时会使用 G0 的栈空间，全局变量的 G0 是 M0 的 G0。 调度时机 抢占式调度 sysmon检测到协程运行过久(比如sleep，死循环) 切换到g0，进入调度循环 主动调度 新起一个协程和协程执行完毕触发调度循环 主动调用runtime.Gosched()切换到g0，进入调度循环 垃圾回收之后。stw之后，会重新选择g开始执行 被动调度 系统调用(比如文件IO)阻塞(同步)，阻塞G和M，P与M分离，将P交给其它M绑定，其它M执行P的剩余G 网络IO调用阻塞(异步) ，阻塞G，G移动到NetPoller，M执行P的剩余G atomic/mutex/channel等阻塞(异步)，阻塞G，G移动到channel的等待队列中，M执行P的剩余G 如何挑选下一个执行的 Goroutine 每执行61次调度循环，从全局队列获取G，若有则直接返回 从P上的runnext看一下是否有G，若有则直接返回 从P上的本地队列看一下是否有G，若有则直接返回 上面都没查找到时，则去全局队列、网络轮询器查找或者从其他Р中窃取,t一直阻塞直到获取到一个可用 的G为止 netpoller中拿到的G是 _Gwaiting状态（存放的是因为网络IO被阻塞的G)，从其它地方拿到的是_Grunnable状态\nGoroutine 的调度方式 基于协作的抢占式调度流程（1.2 版本实现） 编译器会在调用函数前插入runtime.morestack，让运行时有机会在这段代码中检查是否需要执行抢占 调度 Go语言运行时会在垃圾回收暂停程序、系统监控发现Goroutine运行超过10ms，那么会在这个协程设置 一个抢占标记 当发生函数调用时，可能会执行编译器插入的runtime.morestack，它调用的runtime.newstack会检查抢 占标记，如果有抢占标记就会触发抢占让出cpu，切到调度主协程里 只能局部解决问题，只在有函数调用的地方才能插入“抢占”代码（埋点），对于没有函数调用而是纯算法循环计算的 G，Go 调度器依然无法抢占。\n基于信号的抢占式调度（1.14版本实现） M注册一个SIGURG信号的处理函数:sighandler sysmon启动后会间隔性的进行监控，最长间隔10ms，最短间隔20us。如果发现某协程独占 P超过10ms，会给M发送抢占信号 M收到信号后，内核执行sighandler函数把当前协程的状态从_Grunning正在执行改成_Grunnable可执 行，把抢占的协程放到全局队列里，M继续寻找其他goroutine来运行 被抢占的G再次调度过来执行时，会继续原来的执行流 抢占分为_Prunning和_Psyscall\n_Psyscall抢占通常是由于阻塞性系统调用引起的，比如磁盘io、cgo。 _Prunning抢占通常是由于一些类似死循环的计算逻辑引起的。 work staeling \u0026amp; hand off work stealing 机制 当线程M⽆可运⾏的G时，尝试从其他M绑定的 P （每次选择的 P 不一定相同）偷取 G（当前 P 中一半的 G），减少空转，提高了线程利用率。\nhand off 机制 也称为 P 分离机制，当线程 M 因为 G 进行的系统调用阻塞时，线程释放绑定的 P，把 P 转移给其他空闲的 M 执行，也提高了线程利用率。\n","date":"2025-01-13T14:46:19+08:00","permalink":"https://the-oone.github.io/p/go%E5%85%AB%E8%82%A1%E4%B9%8Bgmp%E8%B0%83%E5%BA%A6%E6%A8%A1%E5%9E%8B/","title":"Go八股之GMP调度模型"},{"content":"为什么需要 Goroutine 简单一句话，Goroutine 相比线程拥有更优越的开销性能。\n这里先简单介绍下进程、线程、协程：\n进程：操作系统创建、资源分配的基本单位、同一个进程内的线程会共享资源。 线程：操作系统创建、CPU 调度的基本单位、有独立的堆栈空间 协程：可通过用户程序创建 有栈协程：golang 无栈协程：c++，rust 等 Goroutine 就是一个用户级线程，相比传统线程更加轻量（传统协程 1 MB，Goroutine 约 2 KB）。其不涉及内核态的切换，因此 golang 的并发性能很好。\n如何关闭 Goroutine 关闭 channel\n1 2 // 根据第二个参数进行判别，当关闭 channel 时，根据其返回结果跳出 msg, ok := \u0026lt;-ch 定期轮询 channel\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 func main() { ch := make(chan string, 6) done := make(chan struct{}) go func() { for { select { case ch \u0026lt;- \u0026#34;hello world\u0026#34;: case \u0026lt;-done: close(ch) return } } }() go func() { time.Sleep(3 * time.Second) done \u0026lt;- struct{}{} }() for i := range ch { fmt.Println(\u0026#34;接收到的值：\u0026#34;, i) } fmt.Println(\u0026#34;over\u0026#34;) } 变量 done 作为 channel 类型，用作信号量处理 Goroutine 的关闭。for-loop 结合 select 进行监听，处理完业务之后才会调用 close 关闭 channel。\n使用 context\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 func main() { ch := make(chan struct{}) ctx, cancel := context.WithCancel(context.Background()) go func(ctx context.Context) { for { select { case \u0026lt;-ctx.Done(): ch \u0026lt;- struct{}{} return default: fmt.Println(\u0026#34;hello world\u0026#34;) } time.Sleep(1 * time.Second) } }(ctx) go func() { time.Sleep(4 * time.Second) cancel() }() \u0026lt;-ch fmt.Println(\u0026#34;over\u0026#34;) } 在 context 中，可以借助 ctx.Done 获取一个只读的 channel，可用来识别当前 channel 是否已被关闭。context 对于跨 Goroutine 控制灵活，可以调动 context.WithTimeout 根据时间，或者主动调用 cancel 方法手动关闭。\n如何实现并行 Goroutine 通过设置最大的可同时使用的 CPU 核心数\n1 2 // 设置并行 Goroutine 数量为 2 runtime.GOMAXPROCS(2) 为什么不能大量使用 Goroutine 虽然 Goroutine 的初始栈（自动扩容）很小，但是大部分业务需要更多的栈空间，而频繁的扩容需要很大的成本。 Golang 的 GMP 调度模型中的 M 和 P 是有数量限制的，大量的 Goroutine 会导致过长的调度队列，从而影响性能。 过多的 Goroutine 还会导致频繁的 GC，影响性能。 Goroutine A 能否停止另一个 Goroutine 不能。Goroutine 只有自己主动退出，不能被外界的 Goroutine 关闭。\n父 Goroutine 退出，子 Goroutine 一定会退出嘛 当父 Goroutine 为 main 时，所有的子 Goroutine 都会跟着父 Goroutine 退出 若父 Goroutine 不为 main 时，子 Goroutine 不会跟着父 Goroutine 退出 Goroutine 的状态流转 状态 含义 _Gidle 空闲态 G 刚刚创建，还未初始化 _Grunnable 就绪态 G 在运行队列，等待 M 取出（此时 M 有 P） _Grunning 运行态 M 正在运行 G _Gsyscall 系统调用 M 中运行的 G 发起系统调用（此时 M 无 P） _Gwaiting 阻塞态 G 等待执行资源 _Gdead 完成态 G 已经执行完毕 _Gcopystack 复制栈 G 正获取一个新的栈空间，并将原内容复制过去 Goroutine 泄露 Goroutine 没有被正确的关闭或管理，会导致他们在程序运行过程中无法被回收，最终导致资源浪费和潜在的性能问题\n泄露原因 Goroutine 内部进行 channel/mutex 等读写操作被一直阻塞 Goroutine 内的业务逻辑进入死循环，资源无法释放 Goroutine 内的业务逻辑进入长时间等待，又不断新增的 Goroutine 进入等待 泄露场景 未初始化 channel channel 发送未接收 channel 接收未发送 资源连接未关闭 未成功解锁 死循环 sync.WaitGroup 使用不当 多个协程交替打印奇偶数字 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) func main() { // 创建两个channel用于同步 even := make(chan struct{}) odd := make(chan struct{}) // 创建WaitGroup等待所有协程完成 var wg sync.WaitGroup wg.Add(2) // 打印偶数的协程 go func() { defer wg.Done() for i := 2; i \u0026lt;= 10; i += 2 { \u0026lt;-even // 等待偶数信号 fmt.Printf(\u0026#34;偶数: %d\\n\u0026#34;, i) odd \u0026lt;- struct{}{} // 发送奇数信号 } // 最后一次打印完需要再消费一次even channel,避免死锁 \u0026lt;-even }() // 打印奇数的协程 go func() { defer wg.Done() for i := 1; i \u0026lt;= 9; i += 2 { fmt.Printf(\u0026#34;奇数: %d\\n\u0026#34;, i) even \u0026lt;- struct{}{} // 发送偶数信号 \u0026lt;-odd // 等待奇数信号 } // 最后发送一次信号给偶数协程,让其能够退出 even \u0026lt;- struct{}{} }() // 等待所有协程完成 wg.Wait() // 关闭channel close(even) close(odd) } ","date":"2025-01-12T16:55:26+08:00","permalink":"https://the-oone.github.io/p/go%E5%85%AB%E8%82%A1%E4%B9%8Bgoroutine/","title":"Go八股之Goroutine"},{"content":"String String 的底层数据结构是 int 和 SDS（Simple Dynamic String），相比 C 的原生字符串，增加了以下功能\n保存二进制文件 获取字符串长度的时间复杂度是 O(1) SDS API 内存安全，保证不会造成缓冲区溢出 内部编码 int，若字符串保存的是整数值，并且可以转换为 long，那么该字符串对象的编码被设置为 int。\nembstr，若字符串长度小于等于 44 字节（博主测试环境为 Redis 7.4.1），那么使用 embstr 编码，一次内存分配。只读，修改内容需先转换 raw 编码。\nraw，若字符串长度大于 44 字节，那么使用 raw 编码，两次内存分配。\n常用指令 SET\n设置 key 为字符串值。 如果 key 已有值，无论其类型如何，都会被覆盖。 在 SET 操作成功后，之前与键值相关的任何生存时间都将被丢弃。\n1 2 SET key value [NX | XX] [GET] [EX seconds | PX milliseconds | EXAT unix-time-seconds | PXAT unix-time-milliseconds | KEEPTTL] EX \u0026ndash; 设置指定的过期时间，以秒（正整数）为单位。 PX \u0026ndash; 设置指定的过期时间，以毫秒（正整数）为单位。 EXAT \u0026ndash; 设置指定的密钥过期时间，以秒（正整数）为单位。 PXAT \u0026ndash; 设置密钥过期的 Unix 时间，以毫秒为单位（正整数）。 NX \u0026ndash; 当且仅当 key 不存在时才设置。 XX \u0026ndash; 无论如何都会设置 key。 KEEPTTL \u0026ndash; 继承上一个 key 的有效时间。 GET \u0026ndash; 返回存储在密钥中的旧字符串，如果密钥不存在，则返回 nil。 如果键值不是字符串，会返回错误并中止 SET。 MSET / MSETNX\n将给定的键设置为各自的值。 两者都是原子式的，因此所有给定键都会被一次性设置。\n1 2 MSET key value [key value ...] MSETNX key value [key value ...] # key 必须均不存在 INCR / INCRBY\n对 key 中存储数字进行加法操作，如果键不存在，则在执行操作前将其设置为 0。\n1 2 INCR key # 将存储在键上的数字递增 1。 INCRBY key increment # 将存储在键上的数字递增 increment DECR / DECRBY\n对 key 中存储数字进行减法操作，如果键不存在，则在执行操作前将其设置为 0。\n1 2 DECR key # 将存储在键上的数字递减 1。 DECRBY key increment # 将存储在键上的数字递减 increment GET / MGET\n获取 key 的值。 如果键不存在，则返回特殊值 nil。\n1 2 GET key MGET key [key ...] 应用场景 缓存对象\n计数器\n分布式锁\n若 key 不存在，则显示插入成功，表示加锁成功\n若 key 存在，则显示插入失败，表示加锁失败\n需要配合 Lua 脚本实现原子性\n共享 Session 信息\nList List 是简单的字符串列表（按照插入顺序排序），可以从头部或者尾部向 List 添加元素，链表最大长度为 $2^{32}-1$\n内部实现 3.2 版本之前由双向链表或压缩链表实现。 3.2 版本之后由 QuickList 实现。其是多个节点（压缩列表）组成的双向链表，每个元素可以是一个整数或一个字节数组。 常用指令 LPUSH / RPUSH\n将所有指定值插入存储在 key 处的列表头部。 如果 key 不存在，则在执行推送操作前将其创建为空列表。 如果 key 持有的值不是 list，则会返回错误信息。\n1 LPUSH/RPUSH key element [element ...] LPUSH 命令\tRPUSH 命令 LPUSHX / RPUSHX\n仅在 key 已存在并持有一个列表的情况下，在 key 所在列表的首部插入指定值。 如果 key 不存在，则不会执行任何操作。\n1 LPUSHX/RPUSHX key element [element ...] LPOP / RPOP\n删除并返回存储在 key 处的列表的 最初/最后 一个元素。 默认情况下，该命令从列表 头部/尾部 弹出一个元素。 如果提供了可选的 count 参数，则根据列表的长度，回复最多包含 count 个元素。\n1 LPOP/RPOP key [count] BLPOP / BRPOP\nBLPOP/BRPOP 是一种阻塞列表弹出原语。 它是 LPOP/RPOP 的阻塞版本，因为当没有元素从任何给定列表中弹出时，它会阻塞连接。 元素会从第一个非空列表的 头部/尾部 弹出，并按照给定键的顺序进行检查。\n1 BLPOP/RLPOP key [key ...] timeout LINDEX\n返回存储在 key 中的列表中位于 index 索引处的元素。 索引以 0 为单位，因此 0 表示第一个元素，1 表示第二个元素，以此类推。 负指数可用于指定从列表尾部开始的元素。 这里，-1 表示最后一个元素，-2 表示倒数第二个元素，以此类推。\n1 LINDEX key index LLEN\n返回存储在 key 处的 list 的长度。 如果 key 不存在，则将其解释为空列表，并返回 0。 如果 key 中存储的值不是 list，则会返回错误信息。\n1 LLEN key LRANGE\n返回存储在 key 处的列表的指定元素。 偏移量 start 和 stop 是基于 0 的索引，0 代表列表的第一个元素（列表的头），1 代表下一个元素，以此类推。 这些偏移量也可以是负数，表示从列表的末尾开始的偏移量。 例如，-1 是列表的最后一个元素，-2 是倒数第二个元素，以此类推。\n1 LRANGE key start stop LREM\n从存储在 key 处的列表中移除与元素相同的元素的第一个出现次数。 计数参数对操作的影响如下：count \u0026gt; 0：删除从头部移到尾部的与元素相同的元素。 count \u0026lt; 0：删除从尾部移到头部的与元素相同的元素。 例如，LREM list -2 \u0026ldquo;hello \u0026ldquo;将删除存储在 list 中的 \u0026ldquo;hello \u0026ldquo;的最后两次出现。 请注意，不存在的键会被当作空 list 处理。\n1 LREM key count element LTRIM\n裁剪现有列表，使其只包含指定范围的元素。 start 和 stop 都是基于 0 的索引，其中 0 代表列表的第一个元素（头部），1 代表下一个元素，依此类推。 例如，LTRIM foobar 0 2 将修改存储在 foobar 处的列表，使其只保留列表的前三个元素： start 和 end 也可以是负数，表示与列表末尾的偏移量，其中 -1 表示列表的最后一个元素，-2 表示倒数第二个元素，依此类推。 超出范围的索引不会产生错误：如果 start 大于列表末尾，或 start \u0026gt; end，结果将是一个空列表（导致键被移除）。 如果 end 大于列表末尾，Redis 会将其视为列表的最后一个元素。\n1 LTRIM key start stop LSET\n将索引处的列表元素设置为指定值。\n1 LSET key index element LINSERT\n将元素插入存储在 key 处的列表中的参考值 pivot 之前或之后。 如果 key 不存在，则视为空列表，不执行任何操作。 如果 key 存在但不包含列表值，则返回错误信息。\n1 LINSERT key \u0026lt;BEFORE | AFTER\u0026gt; pivot element BRPOPLPUSH\nBRPOPLPUSH 是 RPOPLPUSH 的阻塞变体。 当源代码包含元素时，该命令的行为与 RPOPLPUSH 完全相同。 在 MULTI/EXEC 块内使用时，该命令的行为与 RPOPLPUSH 完全相同。 当源为空时，Redis 会阻塞连接，直到有其他客户端向其推送或超时。 如果超时为零，则会无限期阻塞。\n1 BRPOPLPUSH source destination timeout 应用场景 消息队列 消息保存：LPUSH + RPOP / RPUSH+LPOP 实现消息队列（使用 BRPOP 命令进行阻塞式读取，减少消费者性能损失） 重复消息处理：生产者实现全局唯一 ID 消息可靠性：BRPOPLPUSH（使得消费者从一个 List 中读取消息，同时 Redis 还会把消息再插入到另一个 List 留存） List 不支持多个消费者消费同一条信息 Hash Hash 是一个 key-value 集合，\n内部实现 listpack\thashtable 如果 Hash 元素小于 512（默认） 个，所有值小于 64 字节（默认）时，Redis 会使用 listpack 作为底层数据结构。 剩余情况，Redis 会使用 hashtable实现 常用命令 HSET / HSETNX\n将指定字段的值设置为存储在 key 的哈希值中各自的值。 HSET 会覆盖哈希值中存在的指定字段的值，HSETNX 对于已存在的字段操作无效。 如果 key 不存在，则会创建一个新的散列键。\n1 2 HSET key field value [field value ...] HSETNX key field value HGET / HMGET / HGETALL\nHGET/HMGET 返回键存储的哈希值中与字段相关的值。 对于散列中不存在的每个字段，都会返回一个 nil 值。 由于不存在的键被视为空哈希值，因此针对不存在的键运行 HMGET 将返回一个 nil 值列表。\nHGETALL 返回存储在 key 处的哈希值的所有字段和值。\n1 2 3 HGET key field HMGET key field [field ...] HGETALL key HDEL\n从存储在 key 中的哈希值中删除指定字段。 不存在于散列中的指定字段将被忽略。 如果没有字段，则删除散列。 如果键不存在，则将其视为空散列，此命令返回 0。\n1 HDEL key field [field ...] HLEN\n返回存储在 key 中的哈希值所包含字段的数量。\n1 HLEN key HEXISTS\n如果字段是存储在 key 处的哈希值中的现有字段，则返回 1，否则返回 0。\n1 HEXISTS key field HKEYS / HVALS\nHKEYS 返回存储在 key 处的哈希值中的所有字段名。\nHVALS 返回键存储的哈希值中的所有值。\n1 2 HKEYS key HVALS key HINCRBY / HINCRBYFLOAT\nHINCRBY 按增量递增存储在 key 的哈希值中的字段数字。 如果 key 不存在，则会创建一个新的哈希值键。 如果字段不存在，则在执行操作前将其值设置为 0。\nHINCRBYFLOAT 按指定增量递增存储在键值处的散列指定字段，该字段代表一个浮点数。 如果增量为负值，结果是哈希字段值递减而不是递增。 如果字段不存在，则在执行操作前将其设置为 0。\n1 2 HINCRBY key field increment HINCRBYFLOAT key field increment 应用场景 缓存对象 (key，field，value) 对应 (对象，属性，值) 购物车 添加商品：HSET cart:{user_id}{goods_id} 1 增加数量：HINCRBY cart:{user_id}{goods_id} 2 商品总数：HLEN cart:{user_id} 删除商品：HDEL cart:{user_id} {goods_id} 获取所有商品：HGETALL cart:{usert_id} Set Set 是一个集合（最多支持存储 $2^{32}-1$ 个元素），其中元素无序、唯一。除了支持集合内的增删改查，还支持多个集合交集、并集、差集。\n内部实现 如果集合元素都是整数，并且元素个数小于 512（默认），Redis 会使用 整数集合作为底层数据结构。 其他情况，Redis 会使用 listpack 作为底层数据结构 intset\tlistpack 常用命令 SADD\n将指定的成员添加到存储在 key 处的集合中。 如果指定的成员已经是这个集合的成员，则会被忽略。 如果 key 不存在，则会先创建一个新集合，然后再添加指定的成员。 如果存储在 key 中的值不是一个集合，则会返回错误信息。\n1 SADD key member [member ...] SREM\n从存储在 key 处的集合中删除指定的成员。 不属于此集合的指定成员将被忽略。 如果 key 不存在，则将其视为空集，此命令返回 0。\n1 SREM key member [member ...] SMEMBERS\n返回存储在 key 处的集合值的所有成员。\n1 SMEMBERS key SISMEMBER\n返回成员是否是存储在 key 中的集合的成员。\n1 SISMEMBER key member SCARD\n返回存储在 key 处的集合的元素个数。\n1 SCARD key SRANDMEMBER / SPOP\nSRANDMEMBER 将从存储在 key 处的集合值中随机返回 count 个元素，元素不从 key 中删除。\nSPOP 将从存储在 key 处的集合值中随机返回 count 个元素，元素从 key 中删除。\n1 2 SRANDMEMBER key [count] SPOP key [count] SMOVE\n将成员从源集合移动到目标集合。 该操作是原子操作。 如果源集合不存在或不包含指定元素，则不执行任何操作，并返回 0。 否则，该元素将从源集合中删除，并添加到目标集合中。 如果指定的元素已存在于目标集合中，则只会从源集合中移除。 如果源集合或目标集合中不存在集合值，则会返回错误信息。\n1 SMOVE source destination member SINTER / SINTERSTORE\nSINTER 返回所有给定集合的交集所产生的集合的成员。\nSINTERSTORE 该命令等同于 SINTER，但不是返回结果集，而是将其存储在目的地中。 如果目的地已经存在，则会被覆盖。\n1 2 SINTER key [key ...] SINTERSTORE destination key [key ...] 应用场景 点赞（元素唯一） 共同好友（集合运算） 数据量较大时，可以让从库进行集合运算，将结果返回给客户端，防止 Redis 阻塞。 抽奖（元素唯一，去重） Zset Zset 相较于 Set 多了个排序属性 score，每个存储元素相当于两个值组成，一个是有序集合的元素值，一个是排序值。\n内部实现 若 Zset 中元素小于 128 个，且每个元素小于 64 字节，Redis 使用 listpack 作为底层数据结构。 剩余情况，Redis 会使用 listpack\tskiplist 常用命令 ZADD\n将具有指定分数的所有指定成员添加到存储在 key 处的排序集合中。 可以指定多个分数/成员对。 如果指定的成员已经是排序集合的成员，则会更新得分，并将元素重新插入正确的位置，以确保排序正确。 如果 key 不存在，则会创建一个新的排序集合，并将指定的成员作为唯一成员，就像排序集合为空一样。 如果键存在，但没有排序集，则会返回错误信息。 分数值应是双精度浮点数的字符串表示。 +inf 和 -inf 值也是有效值。\n1 ZADD key [NX | XX] [GT | LT] [CH] [INCR] score member [score member ...] XX: 只更新已存在的元素，不添加新元素。 NX: 只添加新元素，不更新已存在的元素。 LT: 只在新分数小于当前分数时更新现有元素。此标记不会阻止添加新元素。 GT: 仅在新分数大于当前分数时更新现有元素。 此标记不会阻止添加新元素。 CH: 将返回值从增加的新元素数量修改为改变的元素总数（CH 是 changed 的缩写）。 更改的元素是指新增的元素和已存在的元素，这些元素的分值已被更新。 因此，命令行中指定的元素如果得分与过去相同，则不计算在内。 注意：通常情况下，ZADD 的返回值只计算新增元素的数量。 INCR: 指定该选项时，ZADD 的作用与 ZINCRBY 类似。 在这种模式下，只能指定一个分数元素对。 ZREM\n从存储在 key 中的排序集合中删除指定的成员。 如果 key 存在但没有排序集，则会返回错误信息。\n1 ZREM key member [member ...] ZSCORE\n返回排序集合中 key 处成员的得分。 如果排序集合中不存在成员或 key 不存在，则返回 nil。\n1 ZSCORE key member ZCARD\n返回存储在 key 处的排序集的元素个数。\n1 ZCARD key ZINCRBY\n用增量递增键值存储的排序集合中成员的得分。 如果成员不存在于排序集合中，则会以增量作为其得分（就像它之前的得分是 0.0）。 如果 key 不存在，则会创建一个以指定成员为唯一成员的新排序集。 如果 key 存在但不包含排序集，则会返回错误信息。 分数值应是数值的字符串表示，并接受双精度浮点数。 可以提供一个负值来递减分数。\n1 ZINCRBY key increment member ZRANGE\n返回存储在 key 中的排序集合中元素的指定范围。 ZRANGE 可以执行不同类型的范围查询：按索引（秩）、按分数或按词典顺序。\n默认情况下，该命令执行索引范围查询。 start 和 stop 参数代表基于零的索引，其中 0 代表第一个元素。 这些参数指定了一个包含范围，例如，ZRANGE myzset 0 1 将同时返回排序集的第一个和第二个元素。 索引也可以是负数，表示从排序集末尾开始的偏移量，-1 表示排序集的最后一个元素。\n当提供 BYSCORE 选项时，命令的行为与 ZRANGEBYSCORE 类似，返回排序集中分数等于或介于 start 和 stop 之间的元素范围。\n使用 REV 选项会反转排序集，索引 0 将作为得分最高的元素。\n当使用 BYLEX 选项时，命令的行为与 ZRANGEBYLEX 类似，并返回排序集合中 start 和 stop 之间的元素范围。 请注意，词典排序依赖于所有元素具有相同的分数。 有效的 start 和 stop 必须以 ( 或 [ 开头，以便分别指定范围区间是排他的还是包含的。\n1 ZRANGE key start stop [BYSCORE | BYLEX] [REV] [LIMIT offset count] [WITHSCORES] ZUNIONSTORE / ZDIFFSTORE\n1 2 ZUNIONSTORE destination numkeys key [key ...] [WEIGHTS weight [weight ...]] [AGGREGATE \u0026lt;SUM | MIN | MAX\u0026gt;] # 并集 ZDIFFSTORE destination numkeys key [key ...] # 第一个集合和之后集合的差集 应用场景 排行榜（有序唯一）\n电话、姓名排序\nBitMap BitMap 是一串连续的二进制数组，可以通过偏移量定位元素，适合数据量大且使用二值统计的场景。\n内部实现 String 类型是会保存为二进制的字节数组\n常用命令 SETBIT\n设置或清除存储在 key 处字符串值偏移量的位。 位的设置或清除取决于值，值可以是 0 或 1。当 key 不存在时，将创建一个新的字符串值。 字符串的增长是为了确保它能容纳偏移量处的位。 偏移参数必须大于或等于 0，且小于 2^32（这将位图限制在 512MB）。\n1 SETBIT key offset value GETBIT\n返回存储在 key 处的字符串值中偏移量处的比特值。\n1 GETBIT key offset BITCOUNT\n获取指定范围内值为 1 的个数，默认以字节为单位。\n1 BITCOUNT key [start end [BYTE | BIT]] BITOP\n在多个键（包含字符串值）之间执行位操作，并将结果存储到目标键中。\n1 BITOP \u0026lt;AND | OR | XOR | NOT\u0026gt; destkey key [key ...] 应用场景 签到统计\n判断用户登陆态\nHyperLogLog HyperLogLog 是一种用于统计基数的数据集合类型，基数统计就是指统计一个集合中不重复的元素个数。HyperLogLog 的统计规则基于概率完成，标准误算率为 0.81%。\n内部实现 ^ - ^\n常见命令 PFADD\n将所有元素参数添加到存储在作为第一个参数指定的变量名下的 HyperLogLog 中。\n1 PFADD key [element [element ...]] PFCOUNT\n使用单键调用时，返回存储在指定变量中的 HyperLogLog 的基数估算值，如果变量不存在，则返回 0。 使用多键调用时，通过内部合并存储在所提供键中的 HyperLogLog 成一个临时的 HyperLogLog，返回所传递的 HyperLogLog 联合的基数估算值。\n1 PFCOUNT key [key ...] PFMERGE\n将多个 HyperLogLog 值合并为一个 HyperLogLog 。如果目标 HyperLogLog 不存在（默认为空 HyperLogLog），则创建。 如果存在，则将其视为源集之一。\n1 PFMERGE destkey [sourcekey [sourcekey ...]] 应用场景 网页用户访问(UV)计数 GEO 主要用于存储地理信息\n内部实现 底层复用 Zset，使用 GeoHash 实现了经纬度到 Zset 中元素的权重分数的转换，关键机制是 二维地图区间划分 和 区间编码 。地理位置转换为经纬度后，使用区间编码标识，并将编码值作为 Zset 的权重分数。\n常用命令 GEOADD\n存储指定的地理位置信息，将经度，纬度，位置名称添加到指定的 key 中\n1 GEOADD key [NX | XX] [CH] longitude latitude member [longitude latitude member ...] XX: 只更新已存在的元素，从不添加元素。 NX: 不更新已存在的元素。 CH: 不更新已存在的元素。 总是添加新元素： 将返回值从添加的新元素数修改为更改的元素总数。 更改的元素是指新增的元素和坐标已更新的已有元素。 GEOPOS\n返回关键字处排序集所代表的地理空间索引中所有指定成员的位置（经度、纬度）。\n1 GEOPOS key [member [member ...]] GEODIST\n返回排序集所代表的地理空间索引中两个成员之间的距离。 单位必须是以下之一，默认为米：m 表示米。 km 表示公里。 mi 表示英里。 ft 表示英尺。\n1 GEODIST key member1 member2 [M | KM | FT | MI] GEORADIUS\n返回使用 GEOADD 填充了地理空间信息的排序集合的成员，这些成员位于以中心位置和距中心最大距离（半径）指定的区域边界内。\n1 2 3 GEORADIUS key longitude latitude radius \u0026lt;M | KM | FT | MI\u0026gt; [WITHCOORD] [WITHDIST] [WITHHASH] [COUNT count [ANY]] [ASC | DESC] [STORE key | STOREDIST key] 应用场景 位置信息服务 Stream 专为消息队列设计的数据类型，支持消息持久化、自动生成全局唯一 ID、支持 ACK 确认消息、支持消费组模式\n内部实现 ^ - ^\n常见命令 XADD\n将指定的数据流条目添加到指定键的数据流中。 如果键值不存在，则使用流的值创建键值。 可以使用 NOMKSTREAM 选项禁用创建数据流键。\n1 2 XADD key [NOMKSTREAM] [\u0026lt;MAXLEN | MINID\u0026gt; [= | ~] threshold [LIMIT count]] \u0026lt;* | id\u0026gt; field value [field value ...] XLEN\n返回数据流中的条目数。 如果指定的键不存在，命令将返回 0。\n1 XLEN key XREAD / XREADGROUP\nXREAD 从一个或多个数据流中读取数据，只返回 ID 大于调用者报告的最后接收 ID 的条目。 该命令有一个选项，可在项目不可用时阻塞。\nXREADGROUP 命令是 XREAD 命令的一个特殊版本，支持消费者组。\n1 2 XREAD [COUNT count] [BLOCK milliseconds] STREAMS key [key ...] id [id ...] XREADGROUP GROUP group consumer [COUNT count] [BLOCK milliseconds] [NOACK] STREAMS key [key ...] id [id ...] XDEL\n从数据流中删除指定条目，并返回已删除条目的数量。\n1 XDEL key id [id ...] XRANGE\n该命令返回与给定 ID 范围匹配的数据流条目。\n1 XRANGE key start end [COUNT count] XPENDING / XACK\nXPENDING 查询每个消费组内所有消费者 已读取、尚未确认 的消息。\nXACK 向消息队列确认消息处理已完成\n1 2 XPENDING key group [[IDLE min-idle-time] start end count [consumer]] XACK key group id [id ...] ","date":"2024-12-18T21:30:01+08:00","permalink":"https://the-oone.github.io/p/redis-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/","title":"Redis 数据类型"},{"content":"Redis 简介 Redis（REmote DIctionary Serve）是一个开源的基于内存的 Key-Value 数据库，常常用于缓存、消息队列、分布式锁等场景。除此之外，Redis 还支持事务、持久化、Lua 脚本、集群（主从、哨兵、切片）、发布/订阅等等。\nRedis 对比 Memcached Redis Memcached 数据类型 String、Hash、Lits、Set、ZSet、Bitmap\nHyperLogLog、GEO、Stream String、Integer、ByteArray、List、Set 持久化 原生支持（AOF、RDB） 原生不支持 集群 原生支持（主从复制、哨兵、切片） 原生不支持 其他功能 发布/订阅、Lua 脚本、事务等等 —— Redis 使用场景 相关资料 Redis 官网\nRedis Github 地址\nRedis 在线服务\nRedis 中文文档\n","date":"2024-12-16T20:29:41+08:00","permalink":"https://the-oone.github.io/p/redis%E7%AE%80%E4%BB%8B/","title":"Redis简介"},{"content":"需求 目前负责一个 Web 项目，该项目前后端是分离的，但是只给了一个端口和服务器进行远程连接。所以问题就出现了，前端需要一个端口用于用户访问，而后端也需要一个端口来和前端进行数据传输，那么就需要至少两个端口才能开启这个 Web 服务。为了解决这个问题，在网上查找资料发现 nginx 可以通过反向代理来实现同一个端口访问不同的服务。话不多说，直接开搞！\n方案 Nginx 安装 博主的服务器是 Ubuntu 22.04.4 LTS ，首先更新一下系统软件包\n1 2 3 4 sudo apt update # 更新软件包列表 sudo apt upgrade # 更新软件包 sudo apt install nginx # 安装 nginx 输入 nginx -v 命令，如果能看到 nginx 的版本号，则安装成功\n安装好之后 Nginx一般会自动打开，如果没有可以使用命令手动打开。（注意如果你开启了防火墙，则需要配置防火墙允许 Nginx可以使用的端口的传输流量。）\n1 2 3 4 5 6 sudo systemctl status nginx # 查看 nginx 状态 sudo systemctl start nginx # 启动 nginx sudo systemctl stop nginx # 关闭 nginx sudo systemctl reload nginx # 重新加载配置文件（不中断服务） sudo systemctl restart nginx # 重启 nginx Nginx 配置 进入你的 Nginx 配置文件，博主是在 /etc/nginx/sites-available/default 文件中修改的配置。\n1 sudo vim /etc/nginx/sites-available/default 以下是博主的配置，前端服务配置在 / 根路径下，后端配置在 /api/ 路径下。这样我们就可以通过 http://127.0.0.1/ 访问前端服务，http://127.0.0.1/api/ 访问后端服务。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 server { listen 80; # 监听端口 server_name 127.0.0.1; # 此处填写你的项目的域名或者 IP location / { # 默认访问路径 proxy_pass http://127.0.0.1:5173; # 该项目对外暴露的接口路径 proxy_set_header Host $host; proxy_set_header X-realIP $remote_addr; proxy_set_header X-Forwarded-for $proxy_add_x_forwarded_for; } location /api/ { proxy_pass http://127.0.0.1:5000; # 该项目对外暴露的接口路径 proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } 最终实现效果如下：\n","date":"2024-12-07T20:20:34+08:00","permalink":"https://the-oone.github.io/p/nginx-%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86/","title":"Nginx 反向代理"},{"content":"图床 博客除了文字之外还有图片，但是由于图片的位置是在本地上，因此当上传至网站上时是没办法访问到这些图片的。而图床就可以解决这个问题，其本质上就是一个可以被互联网访问的存放图片的空间。\n大致可以分为下面几类：\n公共图床：只需要上传图片即可，网站会返回给你图片的 URL，例如 Hello图床 。简单方便，但是不太稳定，并且有一些上传限制。\n代码托管平台：类似于 GitHub，Gitee 这种。\n云服务器：类似于阿里云、腾讯云、华为云这些。\n本来想省心直接使用阿里云服务器，看了眼价格之后，默默放弃了（学生党伤不起~）。最后还是选择了 GitHub 作为图床，除了在国内访问不便之外其他方面都还好。\nGitHub 搭建图床 首先需要一个 GitHub 仓库，仓库名随意，设置为 public，建议加上 README 文件，这样默认分支就会变成 main。\n之后需要申请 Token，前往 settings -\u0026gt; Developer Settings -\u0026gt; Personal access tokens 创建一个 token(classic)\n勾选上 repo，如果要考虑安全的话，Token 有效期不要设置永不过期。还有就是注意这个 Token 只有在刚申请的时候才能看到，注意保存，否则只能重新申请一个新的。\nPicGo 这时候我们就可以将图片上传到仓库了，但是每次都需要手动 Git 上传到仓库这样太麻烦了，可以使用 PicGo 这款图片上传和管理工具。点击进入其 GitHub 页面，点击下图位置进去下载页面，选择一个版本下载好。\n之后我们需要将我们的图床设置为 GitHub，图床设置 -\u0026gt; GitHub ，填写好你的配置点击确定即可。\n设定仓库名：你的 GitHub 用户名 / 你的图床仓库名 设定分支名：上传到仓库的那个分支 设定 Token：就是上面我们生成的那个 Token。 设定存储路径：你要将上传的文件放到仓库的那个文件夹下（例如存放在根目录下的 static 目录下，填写 static/）。若存储在根目录下，则不填。 设定自定义域名：https://cdn.jsdelivr.net/gh/user/repo@brach，如果是上传到默认分支，则去掉 @ 及其之后的内容。（这里博主使用了 jsDelivr 来进行加速优化网站打开速度） Typora 实现 CV 自动上传 博主使用的 Typora 支持 PicGo，可以实现在文章内插入图片自动上传至图床。前往 文件 -\u0026gt; 偏好设置\u0026hellip; -\u0026gt; 图像。\n按照图示全部设置完成之后，点击 验证图片上传选项 ，可以看到上传成功\n","date":"2024-12-07T08:45:20+08:00","permalink":"https://the-oone.github.io/p/github-picgo-%E5%9B%BE%E5%BA%8A%E9%85%8D%E7%BD%AE/","title":"GitHub ➕ PicGo 图床配置"},{"content":"准备工作 Hugo\n从 Hugo GitHub 仓库选择合适版本的下载，从下图中所指示位置即可进入下载页面\n选择与你机器对应的版本（我这里选择 0.139.3 版本，windows 系统，对应文件为 hugo_extended_withdeploy_0.139.3_windows-amd64.zip）\n将下载好的文件解压缩，在命令行敲击 hugo version，看到如下结果则表示安装成功。\nGit\n选择合适的版本下载，按照指引一路 next。（由于博主很早之前就已经下载了 Git，所以这块没有图片展示） 创建博客站点 使用 Hugo（建议将其加入环境变量） 创建你的站点，在命令行中输入 hugo new site sitename。出现下图所示，则表明创建好了站点，按照这上面的步骤来即可。\n进入你的站点文件夹，可以看到 Hugo 创建了以下文件\narchetypes 目录包含用于新内容的模板。\nassets 目录包含通常通过资源管道传递的全局资源。包括图片、CSS、Sass、JavaScript 等。\ncontent 目录包含组成站点内容的标记文件（通常是 markdown）和页面资源。\ndata 目录包含用于增强内容、配置、本地化和导航的数据文件（JSON、TOML、YAML 或 XML）。\nhugo.tomal 是 Hugo 的配置文件\ni18n 目录包含多语言站点的翻译表。\nlayouts 目录包含将内容、数据和资源转换为完整网站的模板。\nstatic 目录包含在构建站点时将复制到 public 目录的文件，例如 favicon.ico、robots.txt 和用于验证站点拥有权的文件。在引入页面包和资源管道之前，static 目录也用于存放图片、CSS 和 JavaScript 等资源。\nthemes 目录包含一个或多个主题，每个主题位于自己的子目录中。\nHugo 默认不带主题，因此你需要去 主题社区 下载主题，我这里选择 Stack 这款主题。首先将该文件夹初始为 Git 仓库，再增加主题作为子模块克隆到 theme 文件夹下。使用命令如下：\n初始化仓库：git init -b main\n添加主题：git submodule add https://GitHub.com/CaiJimmy/hugo-theme-stack.git themes/hugo-theme-stack\n将 themes\\hugo-theme-stack\\exampleSite 目录下的 content 文件夹和 hugo.yaml 复制到站点根目录（也就是你上面创建的那个文件夹下，我这里是 myblog），并且删除 hugo.toml 文件。\nNOTE：需要删除 content\\post\\rich-content ，该文件夹内存放的资源访问不了，会导致 Hugo 无法启动）\n使用命令：hugo server -D 启动网站，可以发现站点多了两个文件夹。\npublic 目录包含发布的网站，在运行 hugo 命令时生成。Hugo 根据需要重建此目录及其内容。\nresources 目录包含 Hugo 资源管道的缓存输出，在运行 hugo 或 hugo server 命令时生成。默认情况下，此缓存目录包括 CSS 和图片。Hugo 根据需要重建此目录及其内容。\n访问 http://localhost:1313/，看到如下结果表示你的博客已经在本地搭建好了\nGitHub 部署 搭建好本地环境之后，就需要将网站部署在 GitHub 上。这里有两种部署方式：\n一种是手动上传文件，只需要创建一个 GitHub Page仓库：\n存放网站的静态文件，设置为 Public； 仓库名必须是 \u0026lt;username.github.io\u0026gt;，username 是你 GitHub 的用户名。 创建好仓库之后，按照图示开启 GitHub Page。前往 setting -\u0026gt; Pages -\u0026gt; Branch 选择 main 分支，保存设置。\n将 public 文件夹上传至 GitHub 仓库，上传成功后访问 https://\u0026lt;GiuHub用户名\u0026gt;.github.io，就能看到自己的博客内容了。\n1 2 3 4 5 6 7 git init -b main git add . # git config user.name \u0026#34;your_user_name\u0026#34; # 第一次使用 Git 或者未配置全局变量需要加上此行 # git config user.email \u0026#34;your_user_email\u0026#34; # 第一次使用 Git 或者未配置全局变量需要加上此行 git commit -m \u0026#34;first commit\u0026#34; git remote add origin \u0026lt;your_github_repository_address\u0026gt; git push -u origin main 另一种是 GitHub Action 自动化部署，还需要创建一个博客源文件仓库：\n存放你的网站源文件，建议设置为 Private 防止源码文件泄露\n前往 settings -\u0026gt; Developer Settings -\u0026gt; Personal access tokens 创建一个 token(classic)\n如果要考虑安全的话，Token 有效期不要设置永不过期。还有就是注意勾选上 repo 和 workflow。\n将生成的 Token（注意保存，只有当刚生成时才能看见）加入博客源文件仓库的 secrets 中，前往 Settings -\u0026gt; Secrets and variables -\u0026gt; Actions 设置。\n在站点根目录下创建一个 .github/workflows/xxx.yaml 文件配置工作流\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 name: deploy on: push: branches: - main # 当 main 分支发生 push 的时候，运行下面的 jobs jobs: deploy: runs-on: ubuntu-latest # 运行环境 steps: - name: Checkout uses: actions/checkout@v4 with: fetch-depth: 0 - name: Setup Hugo uses: peaceiris/actions-hugo@v3 with: hugo-version: \u0026#34;0.139.3\u0026#34; # 建议和你下载的 hugo 版本一致 extended: true - name: Build Web run: hugo -D # 使用 hugo 构建静态网页 - name: Deploy Web uses: peaceiris/actions-gh-pages@v4 with: PERSONAL_TOKEN: ${{ secrets.你的Token变量名 }} # 发布到其他 repo 需要提供上面生成的 personal access token EXTERNAL_REPOSITORY: 你的GitHub名/你的仓库名 # 发布到哪个 repo PUBLISH_BRANCH: main # 发布到哪个branch PUBLISH_DIR: ./public # 要发布哪个文件夹的内容 commit_message: auto deploy 将站点根目录下的文件上传至博客源文件仓库，上传成功会出发 GitHub ACtion，自动部署静态页面，访问 https://\u0026lt;GiuHub用户名\u0026gt;.github.io，就能看到自己最新的博客内容了。\n","date":"2024-12-02T18:51:20+08:00","permalink":"https://the-oone.github.io/p/github-pages-hugo-%E9%83%A8%E7%BD%B2%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/","title":"GitHub Pages ➕ Hugo 部署个人博客"}]